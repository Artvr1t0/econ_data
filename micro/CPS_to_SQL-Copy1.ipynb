{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed up\n",
    "\n",
    "Convert the basic monthly CPS datafiles from 1998 to present into a sql database.\n",
    "\n",
    "\n",
    "Updated: February 18, 2018 -- @bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:50:49.312881Z",
     "start_time": "2018-02-19T00:50:45.828163Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Preliminaries and data location\n",
    "import pandas as pd\n",
    "import os, re, struct, sqlite3\n",
    "\n",
    "# Location of data\n",
    "os.chdir('E:/08_Other/Archive/data')\n",
    "\n",
    "# Location of database, if empty, will be created.\n",
    "conn = sqlite3.connect('cps_test.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionaries\n",
    "\n",
    "This section needs some series work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:26:10.356160Z",
     "start_time": "2018-02-19T01:26:10.324918Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Read data dictionary and extract columns of interest\n",
    "s = ['PWORWGT', 'PWCMPWGT', 'HRHHID', 'HURESPLI', 'HRLONGLK', 'HRHHID2', \n",
    "     'PRERNWA', 'PRERNHLY', 'PRTAGE', 'PEAGE', 'PTERNWA', 'PTERNHLY',]\n",
    "s2 = ['HRMONTH', 'PESEX', 'PEMLR', 'PENLFRET', 'PENLFACT', 'PRDISC', 'GESTFIPS',\n",
    "      'HRMIS', 'PRCOW1', 'PRFTLF', 'PREMPNOT', 'PRCIVLF', 'PEJHRSN', 'PEMJOT',\n",
    "      'PEEDUCA', 'PRWKSTAT', 'PRDTOCC1', 'GTMETSTA', 'GEMETSTA']\n",
    "\n",
    "# Regular expressions used to capture pattern in Census data dictionaries\n",
    "p = re.compile('\\n(\\w+)\\s+(\\d+)\\s+(.*?)\\s+.*?(\\d\\d*).*?(\\d\\d+)')\n",
    "\n",
    "# Read the data dictionary file to get the column names and locations\n",
    "dd_open = open('jan03dd.txt', 'r', encoding='iso-8859-1').read()\n",
    "\n",
    "# Regular expression for info of interest based on pattern p\n",
    "dd = [(i[0], int(i[3]), int(i[1])) for i in p.findall(dd_open) if i[0] in (s+s2)]\n",
    "\n",
    "# Manually fix up dictionary\n",
    "dd[6] = ('GTMETSTA', 105, 1)\n",
    "dd[7] = ('PRTAGE', 122, 2) \n",
    "dd[19] = ('PRDTOCC1', 476, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:26:17.966229Z",
     "start_time": "2018-02-19T01:26:17.950606Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Use struct to read files faster \n",
    "def struct_constr(fieldspecs):\n",
    "    \"\"\"Specify which characters to retrieve and which to ignore\"\"\"\n",
    "    unpack_len = 0\n",
    "    unpack_fmt = \"\"\n",
    "    for fieldspec in fieldspecs:\n",
    "        start = fieldspec[1] - 1\n",
    "        end = start + fieldspec[2]\n",
    "        if start > unpack_len:\n",
    "            unpack_fmt += str(start - unpack_len) + \"x\"\n",
    "        unpack_fmt += str(end - start) + \"s\"\n",
    "        unpack_len = end\n",
    "    return struct.Struct(unpack_fmt).unpack_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:26:23.732319Z",
     "start_time": "2018-02-19T01:26:21.669662Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Read single monthly file and convert to pandas dataframe\n",
    "unpack = struct_constr(dd) \n",
    "row_list = []\n",
    "with open('jan04pub.dat', 'r') as file:\n",
    "    for line in file:\n",
    "        row = tuple(map(int, unpack(line.encode())))\n",
    "        if row[-1] > 0:  # Filter out weightless rows\n",
    "            row_list.append(row)\n",
    "    \n",
    "df = (pd.DataFrame(row_list, columns=[v[0] for v in dd])\n",
    "      .apply(pd.to_numeric, downcast='signed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:52:55.569358Z",
     "start_time": "2018-02-19T00:52:53.756702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export to different filetypes\n",
    "df.to_sql('cps_oct16', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:53:14.164591Z",
     "start_time": "2018-02-19T00:53:11.898784Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('cps_oct16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:58:38.231332Z",
     "start_time": "2018-02-19T00:58:38.200089Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_pickle('cps_oct16.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T01:01:50.388561Z",
     "start_time": "2018-02-19T01:01:50.357308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         2\n",
       "2         2\n",
       "3         1\n",
       "4         2\n",
       "5         1\n",
       "6         1\n",
       "7         2\n",
       "8         1\n",
       "9         2\n",
       "10        1\n",
       "11        1\n",
       "12        2\n",
       "13        1\n",
       "14        1\n",
       "15        2\n",
       "16        1\n",
       "17        2\n",
       "18        1\n",
       "19        1\n",
       "20        1\n",
       "21        1\n",
       "22        1\n",
       "23        2\n",
       "24        2\n",
       "25        1\n",
       "26        2\n",
       "27        2\n",
       "28        2\n",
       "29        2\n",
       "         ..\n",
       "104732    2\n",
       "104733    1\n",
       "104734    2\n",
       "104735    1\n",
       "104736    2\n",
       "104737    1\n",
       "104738    2\n",
       "104739    2\n",
       "104740    2\n",
       "104741    1\n",
       "104742    1\n",
       "104743    2\n",
       "104744    1\n",
       "104745    1\n",
       "104746    2\n",
       "104747    1\n",
       "104748    2\n",
       "104749    1\n",
       "104750    2\n",
       "104751    2\n",
       "104752    2\n",
       "104753    1\n",
       "104754    2\n",
       "104755    1\n",
       "104756    2\n",
       "104757    1\n",
       "104758    2\n",
       "104759    1\n",
       "104760    2\n",
       "104761    1\n",
       "Name: PESEX, Length: 104762, dtype: int8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_pickle('cps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T21:54:37.733564Z",
     "start_time": "2018-02-18T21:54:37.702309Z"
    }
   },
   "outputs": [],
   "source": [
    "col_specs = [(i[1], i[1]+i[2]-1) for i in d[2016]]\n",
    "names = [i[0] for i in d[2016]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T22:15:36.687262Z",
     "start_time": "2018-02-18T22:15:32.577556Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_fwf('data/oct16pub.dat', header=None, colspecs=col_specs, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T22:15:44.140985Z",
     "start_time": "2018-02-18T22:15:44.125368Z"
    }
   },
   "outputs": [],
   "source": [
    "df.memory_usage(index=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T23:41:59.143029Z",
     "start_time": "2018-02-18T23:41:56.970979Z"
    }
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "unpk = struct_constr(fieldspecs) \n",
    "with open('data/oct16pub.dat', 'r') as f:\n",
    "    for line in f:       \n",
    "        [int(x) for x in unpacker(line.encode())\n",
    "        if int(raw_fields[-1]) > 0:   # Filter out rows with no weight\n",
    "            l.append(tuple(int(x) for x in raw_fields))\n",
    "            \n",
    "df = pd.DataFrame(l, columns = [f[0] for f in fieldspecs]).apply(\n",
    "    pd.to_numeric, downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T23:42:14.409916Z",
     "start_time": "2018-02-18T23:42:12.300335Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/oct16pub.dat', 'r') as f:\n",
    "    fields = unpacker(line.encode())\n",
    "    df = pd.DataFrame([[int(x) for x in unpacker(line.encode())] \n",
    "                    for line in f if int(unpacker(line.encode())[-1]) > 0], \n",
    "                  columns = [f[0] for f in fieldspecs])\n",
    "#    for col in [f[0] for f in fieldspecs if f[0] in s2]: \n",
    "#        df[col] = df[col].astype('category').cat.as_ordered()\n",
    "    df = df.apply(pd.to_numeric, downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T23:30:37.705668Z",
     "start_time": "2018-02-18T23:30:37.674416Z"
    }
   },
   "outputs": [],
   "source": [
    "#[f[0] for f in fieldspecs if f[0] in s2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T23:30:40.752788Z",
     "start_time": "2018-02-18T23:30:40.737172Z"
    }
   },
   "outputs": [],
   "source": [
    "#fieldspecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:31:53.814247Z",
     "start_time": "2018-02-19T00:31:51.704579Z"
    }
   },
   "outputs": [],
   "source": [
    "unpack = struct_constr(fieldspecs) \n",
    "row_list = []\n",
    "with open('data/oct16pub.dat', 'r') as file:\n",
    "    for line in file:\n",
    "        row = tuple(map(int, unpack(line.encode())))\n",
    "        if row[-1] > 0:  # Filter out weightless rows\n",
    "            row_list.append(r)\n",
    "            \n",
    "            \n",
    "#    d = [[int(s) for s in unpack(r.encode())] for r in f if int(unpack(r.encode())[-1]) > 0]\n",
    "    \n",
    "df = (pd.DataFrame(d, columns=[f[0] for f in fieldspecs])\n",
    "          .apply(pd.to_numeric, downcast='signed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:19:56.562626Z",
     "start_time": "2018-02-19T00:19:56.312605Z"
    }
   },
   "outputs": [],
   "source": [
    "unpack = struct_constr(fieldspecs) \n",
    "d = []\n",
    "with open('data/oct16pub.dat', 'r') as file:\n",
    "    for line in [f for f in file if tuple(map(int, unpack(f.encode())))[-1] > 0]:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:20:30.956259Z",
     "start_time": "2018-02-19T00:20:30.940631Z"
    }
   },
   "outputs": [],
   "source": [
    "tuple(map(int, unpack(line.encode())))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:15:21.851944Z",
     "start_time": "2018-02-19T00:15:21.836318Z"
    }
   },
   "outputs": [],
   "source": [
    "tuple(int(s) for s in unpack(line.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T23:39:52.038300Z",
     "start_time": "2018-02-18T23:39:51.678906Z"
    }
   },
   "outputs": [],
   "source": [
    "mem_usage(df['PRDTOCC1'].replace(-1, np.nan).apply(pd.to_numeric, downcast='unsigned'))#astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T23:39:03.768691Z",
     "start_time": "2018-02-18T23:39:03.753055Z"
    }
   },
   "outputs": [],
   "source": [
    "mem_usage(df['PRDTOCC1'])#.replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:32:08.815524Z",
     "start_time": "2018-02-19T00:32:08.784281Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mem_usage(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:31:07.356886Z",
     "start_time": "2018-02-19T00:31:07.341269Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-19T00:31:13.451125Z",
     "start_time": "2018-02-19T00:31:13.435508Z"
    }
   },
   "outputs": [],
   "source": [
    "df.memory_usage(index=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T23:30:50.222391Z",
     "start_time": "2018-02-18T23:30:50.206764Z"
    }
   },
   "outputs": [],
   "source": [
    "#df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for manual use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T13:21:59.610877Z",
     "start_time": "2018-02-18T13:21:59.407734Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Tools for manual use, as needed\n",
    "\n",
    "# Read a data dictionary in the notebook\n",
    "#print(open(f'data/jan10dd.txt', 'r', encoding='iso-8859-1').read())\n",
    "\n",
    "# Unzip files\n",
    "#from zipfile import ZipFile\n",
    "#for file in [f for f in os.listdir('data/') if f.endswith('pub.zip')]:\n",
    "#    with ZipFile(f'data/{file}', 'r') as zip_ref:\n",
    "#        zip_ref.extractall('data/')\n",
    "\n",
    "# Convert .cps file extension into .dat (early data files end in .cps)\n",
    "#for file in [f for f in os.listdir('data/') if f.endswith('cps')]:\n",
    "#    os.rename(f'data/{file}', f'data/{file[:-4]}.dat')\n",
    "\n",
    "# Drop table from database\n",
    "#c = conn.cursor()\n",
    "#c.execute(\"DROP TABLE cps_2012\")\n",
    "#conn.commit()\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T13:29:04.260789Z",
     "start_time": "2018-02-18T13:29:04.026402Z"
    },
    "code_folding": [
     3,
     18,
     26,
     40,
     49,
     74
    ]
   },
   "outputs": [],
   "source": [
    "# Set of functions for parsing raw data\n",
    "\n",
    "# Use struct to read files faster \n",
    "def struct_constr(fieldspecs):\n",
    "    \"\"\"Build a fast way to read fixed width files\"\"\"\n",
    "    unpack_len = 0\n",
    "    unpack_fmt = \"\"\n",
    "    for fieldspec in fieldspecs:\n",
    "        start = fieldspec[1] - 1\n",
    "        end = start + fieldspec[2]\n",
    "        if start > unpack_len:\n",
    "            unpack_fmt += str(start - unpack_len) + \"x\"\n",
    "        unpack_fmt += str(end - start) + \"s\"\n",
    "        unpack_len = end\n",
    "    field_indices = range(len(fieldspecs))\n",
    "    return struct.Struct(unpack_fmt).unpack_from\n",
    "\n",
    "# Convert valid lines to list\n",
    "def fwf_to_list(file, unpacker, l):\n",
    "    with open(f'data/{file}', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            raw_fields = unpacker(line.encode())\n",
    "            if int(raw_fields[-1]) > 0:   # Filter out rows with no weight\n",
    "                l.append(tuple(int(x) for x in raw_fields))\n",
    "\n",
    "# Convert list of lists to pandas df\n",
    "def list_to_df(l, fieldspecs, year):\n",
    "    \"\"\"Store list as pandas dataframe\"\"\"\n",
    "    df = pd.DataFrame(l, columns = [f[0] for f in fieldspecs]\n",
    "                     ).apply(pd.to_numeric,downcast='unsigned')\n",
    "    for col in [f[0] for f in fieldspecs if f in s2]: \n",
    "        df[col] = df[col].astype('category').cat.as_ordered()\n",
    "    return df\n",
    "\n",
    "# Send pandas df to SQL\n",
    "def df_to_sql(df, year):\n",
    "    \"\"\"Send pandas df to sql database\"\"\"\n",
    "    df.to_sql(f'cps_{year}', conn, if_exists='replace')\n",
    "\n",
    "# Previous two, combined\n",
    "def list_to_sql(l, fieldspecs, year):\n",
    "    \"\"\"Store list into sql database\"\"\"\n",
    "    df = pd.DataFrame(l, columns = [f[0] for f in fieldspecs]\n",
    "                     ).apply(pd.to_numeric,downcast='unsigned')\n",
    "    for col in [f[0] for f in fieldspecs if f in s2]: \n",
    "        df[col] = df[col].astype('category').cat.as_ordered()\n",
    "    df.to_sql(f'cps_{year}', conn, if_exists='replace')\n",
    "\n",
    "# This is source of problem with 2004 and 2012\n",
    "def special_years(year, fs1, fs2, sm):\n",
    "    \"\"\"Handle cases where dictionary is split in middle of year.\n",
    "       Takes two sets of field specifications, and the split month\"\"\"\n",
    "    if year == year:\n",
    "        fieldspecs = fs1\n",
    "        unpacker = struct_constr(fs1)\n",
    "\n",
    "        l = []\n",
    "        # Fill list with monthly data from each monthly file\n",
    "        for file in [f'{calendar.month_name[i].lower()[:3]}{str(year)[2:]}pub.dat' for i in range(1,sm)]:\n",
    "            fwf_to_list(file, unpacker, l)\n",
    "        df2 = list_to_df(l, fs1, year)\n",
    "                        \n",
    "        fieldspecs = fs2\n",
    "        unpacker = struct_constr(fs2)\n",
    "        \n",
    "        l = []\n",
    "        # Fill list with monthly data from each monthly file\n",
    "        for file in [f'{calendar.month_name[i].lower()[:3]}{str(year)[2:]}pub.dat' for i in range(sm,13)]:\n",
    "            fwf_to_list(file, unpacker, l)\n",
    "        df3 = list_to_df(l, fs2, year)\n",
    "        df4 = df2.append(df3)\n",
    "        df_to_sql(df4, year)\n",
    "\n",
    "# Manages the other functions\n",
    "def monthly_to_annual(year):\n",
    "    \"\"\"Read monthly files and store as one annual file\"\"\"\n",
    "    # Field specs (field name, start pos (1-relative), len)\n",
    "    if year not in [2004, 2005, 2012]:\n",
    "        fieldspecs = d[year]\n",
    "        unpacker = struct_constr(fieldspecs)\n",
    "\n",
    "        l = []\n",
    "        # Fill list with monthly data from each monthly file\n",
    "        for file in [f for f in os.listdir('data/') if f.endswith(f'{str(year)[-2:]}pub.dat')]:\n",
    "            fwf_to_list(file, unpacker, l)\n",
    "        list_to_sql(l, fieldspecs, year)\n",
    "        \n",
    "    if year == 2012: special_years(2012, d[2011], d['may12'], 5)\n",
    "    if year == 2005: special_years(2005, d['may04'], d['augnov05'], 8)\n",
    "    if year == 2004: special_years(2004, d['jan03'], d['may04'], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the function to selected years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T13:29:51.296566Z",
     "start_time": "2018-02-18T13:29:08.104897Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#for year in range(1998, 2019):\n",
    "#    monthly_to_annual(year)\n",
    "\n",
    "monthly_to_annual(2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-18T13:30:21.002642Z",
     "start_time": "2018-02-18T13:30:07.298116Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = pd.read_sql(\"SELECT * FROM cps_2004\", conn)#.drop_duplicates())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
