{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Population Survey Microdata using Python\n",
    "\n",
    "March 10, 2018\n",
    "\n",
    "*Note: [IPUMS](https://cps.ipums.org/cps/) is likely the quickest interface for retrieving CPS data. The process below can be avoided by using IPUMS.*\n",
    "\n",
    "*See: Tom Augspurger's [blog](https://tomaugspurger.github.io/tackling%20the%20cps.html) and [github](https://github.com/TomAugspurger/pycps) as the definitive resource for working with CPS microdata in python*\n",
    "\n",
    "If your research requires reading raw CPS microdata, which are stored in fixed-width format text files covering one month each, you can use Python to do so. \n",
    "\n",
    "The [Census FTP page](https://thedataweb.rm.census.gov/ftp/cps_ftp.html) contains the microdata and dictionaries identifying each variable name, location, value range, and whether it applies to a restricted sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:12:03.524274Z",
     "start_time": "2018-03-25T19:12:03.218479Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd  # pandas 0.22\n",
    "import numpy as np\n",
    "import re            # regular expressions\n",
    "import os\n",
    "\n",
    "# Location of data\n",
    "os.chdir('E:/08_Other/Archive/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the January 2017 data dictionary to find variable locations\n",
    "\n",
    "The example will calculate the employment to population ratio for women between the age of 25 and 54 in April 2017. To do this, we need to find the appropriate data dictionary on the Census FTP site, in this case January_2017_Record_Layout.txt, open it with python, and read the text inside. \n",
    "\n",
    "We find that the BLS composite weight is called ```PWCMPWGT```, the age variable is called ```PRTAGE```, the sex variable is called ```PESEX``` and women are identified by '2', and the employment status is stored as ```PREMPNOT```.\n",
    "\n",
    "You may also notice that the dictionary follows a pattern, where variable names and locations are stored on the same line and in the same order. Regular expressions can be used to extract the parts of this pattern that we care about, specifically: the variable name, length, description, and location.\n",
    "\n",
    "The python list ```dd_sel_var``` stores the variable names and locations for the four variables of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:12:03.537285Z",
     "start_time": "2018-03-25T19:12:03.526275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data dictionary \n",
    "dd_file = 'January_2017_Record_Layout.txt'\n",
    "dd_full = open(dd_file, 'r', encoding='iso-8859-1').read()\n",
    "\n",
    "# Series of interest \n",
    "series = ['PWCMPWGT', 'PRTAGE', 'PREMPNOT', 'PESEX']\n",
    "\n",
    "# Regular expression finds rows with variable location details\n",
    "p = re.compile('\\n(\\w+)\\s+(\\d+)\\s+(.*?)\\t+.*?(\\d\\d*).*?(\\d\\d+)')\n",
    "\n",
    "# Keep adjusted results for series of interest\n",
    "dd_sel_var = [(i[0], int(i[3])-1, int(i[4])) \n",
    "              for i in p.findall(dd_full) if i[0] in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:12:03.553300Z",
     "start_time": "2018-03-25T19:12:03.539287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PRTAGE', 121, 123), ('PESEX', 128, 130), ('PREMPNOT', 392, 394), ('PWCMPWGT', 845, 855)]\n"
     ]
    }
   ],
   "source": [
    "print(dd_sel_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the CPS microdata for April 2017\n",
    "\n",
    "There are many ways to accomplish this task. One that is simple for small scale projects and still executes quickly involves using python list comprehension to read each line of the microdata and pull out the parts we want, using the locations from the data dictionary. \n",
    "\n",
    "Pandas is used to make the data structure a bit more human readable and to make filtering the data a bit more intuitive. The column names come from the data dictionary varible ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:12:04.546280Z",
     "start_time": "2018-03-25T19:12:03.555805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert raw data into a list of tuples\n",
    "data = [tuple(int(line[i[1]:i[2]]) for i in dd_sel_var) \n",
    "        for line in open('apr17pub.dat', 'rb')]\n",
    "\n",
    "# Convert to pandas dataframe, add variable ids as heading\n",
    "df = pd.DataFrame(data, columns=[v[0] for v in dd_sel_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benchmarking against BLS published data\n",
    "\n",
    "The last step to show that the example has worked is to compare a sample calculation, the prime age employment rate of women, to the [BLS published version of that calculation](https://data.bls.gov/timeseries/LNU02300062). If the benchmark calculation from the microdata is very close to the BLS result, we can feel a bit better about other calculations that we need to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-25T19:12:04.568794Z",
     "start_time": "2018-03-25T19:12:04.551777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April 2017: 72.3\n"
     ]
    }
   ],
   "source": [
    "# Temporary dataframe with only women age 25 to 54\n",
    "dft = df[(df['PESEX'] == 2) & (df['PRTAGE'].between(25, 54))]\n",
    "\n",
    "# Identify employed portion of group as 1.0 & the rest as 0.0\n",
    "empl = np.where(dft['PREMPNOT'] == 1, 1.0, 0.0)\n",
    "\n",
    "# Take weighted average of employed portion of group\n",
    "epop = np.average(empl, weights=dft['PWCMPWGT']) * 100\n",
    "\n",
    "# Print out the result to check against LNU02300062\n",
    "print(f'April 2017: {round(epop, 1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the U.S. Current Population Survey (CPS)\n",
    "\n",
    "The CPS was initially deployed in 1940 to give a more accurate unemployment rate estimate, and it is still the source of the official unemployment rate. The CPS is a monthly survey of around 65,000 households. Each selected household is surveyed up to 8 times. Interviewers ask basic demographic and employment information for the first three interview months, then ask additional detailed wage questions on the 4th interview. The household is not surveyed again for eight months, and then repeats four months of interviews with detailed wage questions again on the fourth. \n",
    "\n",
    "The CPS is not a random sample, but a multi-stage stratified sample. In the first stage, each state and DC are divided into \"primary sampling units\". In the second stage, a sample of housing units are drawn from the selected PSUs.\n",
    "\n",
    "There are also months were each household receives supplemental questions on a topic of interest. The largest such \"CPS supplement\", conducted each March, is the Annual Social and Economic Supplement. The sample size for this supplement is expanded, and the respondents are asked questions about various sources of income, and about the quality of their jobs (for example, health insurance benefits). Other supplements cover topics like job tenure, or computer and internet use.\n",
    "\n",
    "The CPS is a joint product of the U.S. Census Bureau and the Bureau of Labor Statistics.\n",
    "\n",
    "*Special thanks to John Schmitt for guidance on the CPS.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
