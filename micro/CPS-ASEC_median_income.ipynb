{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPS ASEC replicate Census Median HH Income Estimates\n",
    "\n",
    "Brian Dew, brian.w.dew@gmail.com\n",
    "\n",
    "January 15, 2019\n",
    "\n",
    "----\n",
    "\n",
    "Try to replicate the median household income statistics [published](https://www.census.gov/library/publications/2018/demo/p60-263.html) by Census, using a binned- and weighted-median.\n",
    "\n",
    "The number I want to get (at least very close) is $61,372.\n",
    "\n",
    "\n",
    "Also want to clean up the code a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T22:38:50.148205Z",
     "start_time": "2019-01-27T22:38:49.951655Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries (python 3.6)\n",
    "import os, re, struct\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import wquantiles\n",
    "\n",
    "os.chdir('/home/brian/Documents/ASEC/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T22:38:50.152576Z",
     "start_time": "2019-01-27T22:38:50.149593Z"
    }
   },
   "outputs": [],
   "source": [
    "# read data dictionary text file \n",
    "pubuse_file = 'asec2018_pubuse.dat'\n",
    "dd_file = '08ASEC2018_Data_Dict_Full.txt'\n",
    "data_dict = open(dd_file, 'r', encoding='iso-8859-1').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T22:38:50.183742Z",
     "start_time": "2019-01-27T22:38:50.153755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve column info from dictionary\n",
    "p = re.compile('D (\\w+)\\s+(\\d{1,2})\\s+(\\d+)\\s+')\n",
    "var_key = pd.DataFrame(p.findall(data_dict), columns=['Var', 'Len', 'Loc'])\n",
    "var_key = var_key.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Filter out columns of interest\n",
    "s = ['H_HHTYPE', 'H_SEQ', 'H_TYPE', 'HSUP_WGT', 'HTOTVAL']\n",
    "s_key = var_key[var_key['Var'].isin(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T22:38:52.395084Z",
     "start_time": "2019-01-27T22:38:50.185633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read raw fwf file\n",
    "data = pd.read_fwf(pubuse_file, header=None, names=list(s_key.Var),# nrows=1000,\n",
    "                 colspecs=list(zip(s_key.Loc-1, s_key.Loc + s_key.Len-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T22:38:52.429367Z",
     "start_time": "2019-01-27T22:38:52.401054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Households: 127,586,152\n",
      "2017 Median HH Income: $60,885.12\n"
     ]
    }
   ],
   "source": [
    "# Median Household Income (Close)\n",
    "df = data[data['H_HHTYPE'] == 1]\n",
    "df = df.drop_duplicates(subset='H_SEQ', keep='first')\n",
    "df = df[df['H_TYPE'] <= 8]\n",
    "\n",
    "print(f\"Number of Households: {df.HSUP_WGT.sum()/100:,.0f}\")\n",
    "med_inc = wquantiles.median(df['HTOTVAL'], df['HSUP_WGT'])\n",
    "print(f\"2017 Median HH Income: ${med_inc:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T22:43:46.257382Z",
     "start_time": "2019-01-27T22:43:46.171753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 62500.0\n",
      "weighted median: 60885.11841403385\n",
      "binned, weighted median:  61304.85139687098\n"
     ]
    }
   ],
   "source": [
    "df['wage_range'] = pd.cut(df['HTOTVAL'], list(range(-25000,10000000,5000)), include_lowest=True)\n",
    "df = df.sort_values('HTOTVAL')#.dropna(subset=['wage_range'])\n",
    "midpt = df['HSUP_WGT'].sum() * 0.5\n",
    "df['cs'] = df['HSUP_WGT'].cumsum()\n",
    "print('median: ' + str(df.iloc[(df['cs']-midpt).abs().argsort()[:1]].wage_range.values[0].mid))\n",
    "print('weighted median: ' + str(wquantiles.median(df['HTOTVAL'], df['HSUP_WGT'])))\n",
    "n = list(df['wage_range'].unique()).index(df.iloc[(df['cs']-midpt).abs().argsort()[:1]].wage_range.values[0])\n",
    "lowval = df[df['wage_range'] == list(df['wage_range'].unique())[n-1]].iloc[-1].cs\n",
    "highval = df[df['wage_range'] == list(df['wage_range'].unique())[n]].iloc[-1].cs\n",
    "print('binned, weighted median: ', str((((midpt - lowval) / (highval - lowval)) * 5000) + df.iloc[(df['cs']-midpt).abs().argsort()[:1]].wage_range.values[0].left))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
