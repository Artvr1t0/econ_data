{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPS ASEC replicate Census Median HH Income Estimates\n",
    "\n",
    "Brian Dew, brian.w.dew@gmail.com\n",
    "\n",
    "December 28, 2019\n",
    "\n",
    "----\n",
    "\n",
    "Try to replicate the median household income statistics [published](https://www.census.gov/library/publications/2018/demo/p60-263.html) by Census, using a binned- and weighted-median.\n",
    "\n",
    "The number I want to get (at least very close) is $61,372.\n",
    "\n",
    "\n",
    "Also want to clean up the code a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T14:33:04.621308Z",
     "start_time": "2019-07-07T14:33:04.386762Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, re, struct\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.chdir('/home/brian/Documents/ASEC/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T14:33:04.628416Z",
     "start_time": "2019-07-07T14:33:04.622711Z"
    }
   },
   "outputs": [],
   "source": [
    "# read data dictionary text file \n",
    "pubuse_file = 'asec2018_pubuse.dat'\n",
    "dd_file = '08ASEC2018_Data_Dict_Full.txt'\n",
    "data_dict = open(dd_file, 'r', encoding='iso-8859-1').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T14:33:04.641313Z",
     "start_time": "2019-07-07T14:33:04.630186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve column info from dictionary\n",
    "variables = ['HRECORD', 'HSUP_WGT', 'HTOTVAL']\n",
    "p = re.compile(f'D ({\"|\".join(variables)})\\s+(\\d{{1,2}})\\s+(\\d+)\\s+')\n",
    "cols = {name: (int(start) - 1, int(start) - 1 + int(length)) \n",
    "        for name, length, start in re.findall(p, data_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw fwf file\n",
    "df = (pd.read_fwf(pubuse_file, \n",
    "                  colspecs=list(cols.values()), \n",
    "                  header=None, \n",
    "                  names=cols.keys())\n",
    "        .query('HRECORD == 1 and HSUP_WGT > 0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61136.840550989225"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binned_weighted_percentile(group, percentile=0.5):\n",
    "    \"\"\"Return BLS-styled binned and weighted percentile\"\"\"\n",
    "    weight = 'HSUP_WGT'\n",
    "    wage_var = 'HTOTVAL'\n",
    "    bin_size = 2500\n",
    "    bins = list(np.arange(0, 250000, bin_size))\n",
    "    # Cut wage series according to bins of bin_size\n",
    "    bin_cut = lambda x: pd.cut(x[wage_var], bins, include_lowest=True)\n",
    "    \n",
    "    # Calculate cumulative sum for weight variable\n",
    "    cum_sum = lambda x: x[weight].cumsum()\n",
    "    \n",
    "    # Sort wages then apply bin_cut and cum_sum\n",
    "    df = (group.sort_values(wage_var)\n",
    "               .assign(WAGE_BIN = bin_cut, CS = cum_sum))\n",
    "    \n",
    "    # Find the weight at the percentile of interest\n",
    "    pct_wgt = df[weight].sum() * percentile\n",
    "\n",
    "    # Find wage bin for person nearest to weighted percentile\n",
    "    pct_bin = df.iloc[df['CS'].searchsorted(pct_wgt)].WAGE_BIN\n",
    "    \n",
    "    # Weight at bottom and top of bin\n",
    "    wgt_btm, wgt_top = (df.loc[df.WAGE_BIN == pct_bin, 'CS']\n",
    "                          .iloc[[0, -1]].values)\n",
    "    \n",
    "    # Find where in the bin the percentile is and return that value\n",
    "    pct_value = ((((pct_wgt - wgt_btm) / \n",
    "                   (wgt_top - wgt_btm)) * bin_size) + pct_bin.left)\n",
    "    return pct_value\n",
    "\n",
    "binned_weighted_percentile(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
