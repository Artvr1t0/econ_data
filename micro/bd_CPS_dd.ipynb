{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS data dictionaries\n",
    "\n",
    "bd_CPS_dd.ipynb\n",
    "\n",
    "September 20, 2018\n",
    "\n",
    "@bd_econ\n",
    "\n",
    "Requires: `cps_details.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re\n",
    "import struct\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from cps_details import VarList, DataDict, text_repl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Match CPS microdata files with their data dictionary\n",
    "Matcher = {}\n",
    "\n",
    "DataDict.pop('matcher', None)\n",
    "for dfile, dvals in DataDict.items():\n",
    "    ddf = open(f'dd/{dfile}').read()\n",
    "    if dfile == 'jan98dd.asc':\n",
    "        d = {text_repl(s[0]): [int(s[2])-1, int(s[2])+int(s[1])-1, int(s[1])] \n",
    "             for s in re.findall(dvals['re'], ddf) if s[0] in VarList}\n",
    "    else:\n",
    "        d = {text_repl(s[0]): [int(s[3])-1, int(s[4]), int(s[2])] \n",
    "             for s in re.findall(dvals['re'], ddf)}\n",
    "    \n",
    "    # Suggest dtypes for numpy\n",
    "    for k, v in d.items(): \n",
    "        d[k].append('U4' if k in ['HRSAMPLE']\n",
    "                    else 'U2' if k in ['HRSERSUF']\n",
    "                    else 'f4' if 'WGT' in k\n",
    "                    #else 'f4' if 'PRER' in k\n",
    "                    else 'int8' if v[-1] < 3 \n",
    "                    else 'int16' if v[-1] < 6 \n",
    "                    else 'int32' if v[-1] < 12 \n",
    "                    else 'intp')    \n",
    "    \n",
    "    # Make sure that start and end = length\n",
    "    error_list = [k for k, v in d.items() if v[1] - v[0] != v[2]]\n",
    "    if len(error_list) > 0:\n",
    "        print(f'Error: {dfile}: {\", \".join(error_list)}')\n",
    "    DataDict[dfile]['dd'] = d\n",
    "    \n",
    "    # Add list of related monthly CPS microdata files\n",
    "    mos = pd.date_range(dvals['start'], dvals['end'], freq='MS')\n",
    "    monthly_file_list = [f'{i:%b%y}pub.dat'.lower() for i in mos]\n",
    "    DataDict[dfile]['flist'] = monthly_file_list\n",
    "    \n",
    "    # Add relevant monthly CPS filenames to matcher\n",
    "    for file in monthly_file_list:\n",
    "        Matcher[file] = dfile\n",
    "    \n",
    "    # Stuct unpack format\n",
    "    start, end, width, fmt = zip(*d.values())\n",
    "    skip = ([f'{st - en}x' if (st - en) > 0 else '' \n",
    "             for st, en in zip(start, [0] + list(end[:-1]))])\n",
    "    keep = [f'{w}s' for w in width]\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, keep) for j in i])\n",
    "    DataDict[dfile]['unpack_fmt'] = unpack_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Education groups\n",
    "educ = {'LTHS': [31, 32, 33, 34, 35, 36, 37, 38], \n",
    "        'HS': [39],\n",
    "        'SC': [40, 41, 42],\n",
    "        'COLL': [43],\n",
    "        'ADV': [44, 45, 46]}\n",
    "educ_map = {}\n",
    "for k, v in educ.items():\n",
    "    for i in v:\n",
    "        educ_map.update({i:k})\n",
    "\n",
    "for dfile, dvals in DataDict.items():\n",
    "    DataDict[dfile]['map'] = {}\n",
    "    \n",
    "    # Add education groups\n",
    "    DataDict[dfile]['map']['educ'] = educ_map\n",
    "    \n",
    "    # WBHAO race/ethnic groups from CEPR\n",
    "    start_month = pd.to_datetime(dvals['start'])\n",
    "    if start_month > pd.to_datetime('2012-04-01'):\n",
    "        race = {'White': [1], \n",
    "                'Black': [2, 6, 10, 11, 12, 16, 17, 18, 22, 23], \n",
    "                'Asian': [4, 5, 8, 9, 13, 14, 15, 19, 20, 21, 24], \n",
    "                'Other': [3, 7, 25, 26]}\n",
    "    elif start_month > pd.to_datetime('2002-12-01'):\n",
    "        race = {'White': [1], \n",
    "                'Black': [2, 6, 10, 11, 12, 15, 16, 19], \n",
    "                'Asian': [4, 5, 8, 9, 13, 14, 17, 18], \n",
    "                'Other': [3, 7, 20, 21]}\n",
    "    else:\n",
    "        race = {'White': [1], \n",
    "                'Black': [2], \n",
    "                'Asian': [4], \n",
    "                'Other': [3, 5]}\n",
    "    race_map = {}\n",
    "    for k, v in race.items():\n",
    "        for i in v:\n",
    "            race_map[i] = k\n",
    "    DataDict[dfile]['map']['race'] = race_map\n",
    "    \n",
    "    # Hispanic identification\n",
    "    if start_month > pd.to_datetime('2013-12-01'):\n",
    "        hisp = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    elif start_month > pd.to_datetime('2002-12-01'):\n",
    "        hisp = [1, 2, 3, 4, 5]\n",
    "    else:\n",
    "        hisp = [1, 2, 3, 4, 5, 6, 7]\n",
    "        \n",
    "    DataDict[dfile]['map']['hisp'] = hisp\n",
    "    \n",
    "    # Identify when to calculate ID2 manually\n",
    "    DataDict[dfile]['map']['id2'] = False\n",
    "    if start_month < pd.to_datetime('2004-05-01'):\n",
    "        DataDict[dfile]['map']['id2'] = True\n",
    "\n",
    "    # Identify weight variables for each data dict\n",
    "    wgt_vars = [i for i in dvals['dd'].keys() if 'WGT' in i]\n",
    "    DataDict[dfile]['map']['wgt'] = wgt_vars\n",
    "\n",
    "    # Identify weight variables for each data dict\n",
    "    er_vars = [i for i in dvals['dd'].keys() if 'PRER' in i]\n",
    "    DataDict[dfile]['map']['er'] = er_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T12:16:46.830556Z",
     "start_time": "2018-09-20T12:16:46.721197Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Matcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-32e07419e4f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Generate pickle file with data for reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mDataDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'matcher'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cps_basic_dd.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Matcher' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate pickle file with data for reader\n",
    "DataDict['matcher'] = Matcher\n",
    "\n",
    "with open('cps_basic_dd.pkl', 'wb') as f:\n",
    "    pickle.dump(DataDict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
