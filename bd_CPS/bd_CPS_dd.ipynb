{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS data dictionaries\n",
    "\n",
    "bd_CPS_dd.ipynb\n",
    "\n",
    "October 13, 2018\n",
    "\n",
    "@bd_econ\n",
    "\n",
    "Requires: `cps_details.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T15:07:40.029671Z",
     "start_time": "2018-10-13T15:07:40.026370Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import struct\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from bd_CPS_details import VarList, DataDict, text_repl, StatesMap, RegionsMap\n",
    "\n",
    "os.chdir('/home/brian/Documents/CPS/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T15:07:40.097958Z",
     "start_time": "2018-10-13T15:07:40.031704Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Match CPS microdata files with their data dictionary\n",
    "Matcher = {}\n",
    "\n",
    "DataDict.pop('matcher', None)\n",
    "for dfile, dvals in DataDict.items():\n",
    "    ddf = open(f'{dfile}', 'r', encoding='iso-8859-1').read()\n",
    "    if dfile == 'jan98dd.asc':\n",
    "        d = {text_repl(s[0]): [int(s[2])-1, int(s[2])+int(s[1])-1, int(s[1])] \n",
    "             for s in re.findall(dvals['re'], ddf) if s[0] in VarList}\n",
    "    else:\n",
    "        d = {text_repl(s[0]): [int(s[3])-1, int(s[4]), int(s[2])] \n",
    "             for s in re.findall(dvals['re'], ddf)}\n",
    "    \n",
    "    # Suggest dtypes for numpy\n",
    "    for k, v in d.items(): \n",
    "        d[k].append('U4' if k in ['HRSAMPLE']\n",
    "                    else 'U2' if k in ['HRSERSUF']\n",
    "                    else 'f4' if 'WGT' in k\n",
    "                    #else 'f4' if 'PRER' in k\n",
    "                    else 'int8' if v[-1] < 3 \n",
    "                    else 'int16' if v[-1] < 6 \n",
    "                    else 'int32' if v[-1] < 12 \n",
    "                    else 'intp')    \n",
    "    \n",
    "    # Make sure that start and end = length\n",
    "    error_list = [k for k, v in d.items() if v[1] - v[0] != v[2]]\n",
    "    if len(error_list) > 0:\n",
    "        print(f'Error: {dfile}: {\", \".join(error_list)}')\n",
    "    DataDict[dfile]['dd'] = d\n",
    "    \n",
    "    # Add list of related monthly CPS microdata files\n",
    "    mos = pd.date_range(dvals['start'], dvals['end'], freq='MS')\n",
    "    monthly_file_list = [f'{i:%b%y}pub.dat'.lower() for i in mos]\n",
    "    DataDict[dfile]['flist'] = monthly_file_list\n",
    "    \n",
    "    # Add relevant monthly CPS filenames to matcher\n",
    "    for file in monthly_file_list:\n",
    "        Matcher[file] = dfile\n",
    "    \n",
    "    # Stuct unpack format\n",
    "    start, end, width, fmt = zip(*d.values())\n",
    "    skip = ([f'{st - en}x' if (st - en) > 0 else '' \n",
    "             for st, en in zip(start, [0] + list(end[:-1]))])\n",
    "    keep = [f'{w}s' for w in width]\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, keep) for j in i])\n",
    "    DataDict[dfile]['unpack_fmt'] = unpack_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T15:07:40.126505Z",
     "start_time": "2018-10-13T15:07:40.100429Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Create new/cleaned variables\n",
    "# Education groups\n",
    "educ = {'LTHS': [31, 32, 33, 34, 35, 36, 37, 38], \n",
    "        'HS': [39],\n",
    "        'SC': [40, 41, 42],\n",
    "        'COLL': [43],\n",
    "        'ADV': [44, 45, 46]}\n",
    "educ_map = {}\n",
    "for k, v in educ.items():\n",
    "    for i in v:\n",
    "        educ_map.update({i:k})\n",
    "\n",
    "for dfile, dvals in DataDict.items():\n",
    "    DataDict[dfile]['map'] = {}\n",
    "    \n",
    "    # Add state id map to two letter codes\n",
    "    DataDict[dfile]['map']['state'] = StatesMap\n",
    "    \n",
    "    # Add Census regions map from state two letter codes\n",
    "    DataDict[dfile]['map']['region'] = RegionsMap\n",
    "    \n",
    "    # Add education groups\n",
    "    DataDict[dfile]['map']['educ'] = educ_map\n",
    "    \n",
    "    # WBHAO race/ethnic groups from CEPR\n",
    "    start_month = pd.to_datetime(dvals['start'])\n",
    "    if start_month > pd.to_datetime('2012-04-01'):\n",
    "        race = {'White': [1], \n",
    "                'Black': [2, 6, 10, 11, 12, 16, 17, 18, 22, 23], \n",
    "                'Asian': [4, 5, 8, 9, 13, 14, 15, 19, 20, 21, 24], \n",
    "                'Other': [3, 7, 25, 26]}\n",
    "    elif start_month > pd.to_datetime('2002-12-01'):\n",
    "        race = {'White': [1], \n",
    "                'Black': [2, 6, 10, 11, 12, 15, 16, 19], \n",
    "                'Asian': [4, 5, 8, 9, 13, 14, 17, 18], \n",
    "                'Other': [3, 7, 20, 21]}\n",
    "    else:\n",
    "        race = {'White': [1], \n",
    "                'Black': [2], \n",
    "                'Asian': [4], \n",
    "                'Other': [3, 5]}\n",
    "    race_map = {}\n",
    "    for k, v in race.items():\n",
    "        for i in v:\n",
    "            race_map[i] = k\n",
    "    DataDict[dfile]['map']['race'] = race_map\n",
    "    \n",
    "    # Hispanic identification\n",
    "    if start_month > pd.to_datetime('2013-12-01'):\n",
    "        hisp = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    elif start_month > pd.to_datetime('2002-12-01'):\n",
    "        hisp = [1, 2, 3, 4, 5]\n",
    "    else:\n",
    "        hisp = [1, 2, 3, 4, 5, 6, 7]\n",
    "        \n",
    "    DataDict[dfile]['map']['hisp'] = hisp\n",
    "    \n",
    "    # Major industry group\n",
    "    start_month = pd.to_datetime(dvals['start'])\n",
    "    if start_month > pd.to_datetime('2002-12-01'):\n",
    "        ind = {'Construction and mining': [1, 2, 3],\n",
    "               'Finance and business services': [7, 8, 9, 12],\n",
    "               'Manufacturing': [4],\n",
    "               'Trade, transportation, and utilities': [5, 6],\n",
    "               'Education and health': [10],\n",
    "               'Leisure and hospitality': [11],\n",
    "               'Public administration': [13],\n",
    "               'Armed forces': [14]}\n",
    "    else:\n",
    "        ind = {'Construction and mining': [1, 2, 3, 21],\n",
    "               'Finance and business services': [7, 11, 12, 13, 14, 20],\n",
    "               'Manufacturing': [4, 5],\n",
    "               'Trade, transportation, and utilities': [6, 8, 9, 10],\n",
    "               'Education and health': [16, 17, 18, 19],\n",
    "               'Leisure and hospitality': [15],\n",
    "               'Public administration': [22],\n",
    "               'Armed forces': [23]}    \n",
    "    ind_map = {}\n",
    "    for k, v in ind.items():\n",
    "        for i in v:\n",
    "            ind_map[i] = k\n",
    "    DataDict[dfile]['map']['ind'] = ind_map        \n",
    "        \n",
    "    # Identify when to calculate ID2 manually\n",
    "    DataDict[dfile]['map']['id2'] = False\n",
    "    if start_month < pd.to_datetime('2004-05-01'):\n",
    "        DataDict[dfile]['map']['id2'] = True\n",
    "\n",
    "    # Identify weight variables for each data dict\n",
    "    wgt_vars = [i for i in dvals['dd'].keys() if 'WGT' in i]\n",
    "    DataDict[dfile]['map']['wgt'] = wgt_vars\n",
    "\n",
    "    # Identify weight variables for each data dict\n",
    "    er_vars = [i for i in dvals['dd'].keys() if 'PRER' in i]\n",
    "    DataDict[dfile]['map']['er'] = er_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-13T15:07:40.135230Z",
     "start_time": "2018-10-13T15:07:40.128122Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Generate pickle file with data for reader\n",
    "DataDict['matcher'] = Matcher\n",
    "\n",
    "with open('cps_basic_dd.pkl', 'wb') as f:\n",
    "    pickle.dump(DataDict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
