{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS data dictionaries\n",
    "\n",
    "bd_CPS_dd.ipynb\n",
    "\n",
    "April 14, 2019\n",
    "\n",
    "@bd_econ\n",
    "\n",
    "Requires: `cps_details.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T00:02:48.585506Z",
     "start_time": "2019-04-23T00:02:48.348639Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 0.24.2\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import struct\n",
    "import pickle\n",
    "import pandas as pd\n",
    "print('pandas:', pd.__version__)\n",
    "\n",
    "from bd_CPS_details import VarList, DataDict, text_repl, StatesMap, RegionsMap\n",
    "\n",
    "os.chdir('/home/brian/Documents/CPS/data')\n",
    "\n",
    "# Some variables start in the middle of the jan98dd.asc dictionary\n",
    "# This code splits the jan98dd.asc into two\n",
    "ddf = open('jan98dd.asc', 'r', encoding='iso-8859-1').read()\n",
    "chldvars = 'PRPERTYP \\n     = 2 \\n\\nD PRCHLD    2    633\\n\\nD PRNMCHLD    2    635\\n'\n",
    "ddf = ddf.replace('PRPERTYP \\n     = 2 ', chldvars)\n",
    "with open('jan98dd2.asc', \"w\") as ddm:\n",
    "    ddm.write(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T00:02:48.664584Z",
     "start_time": "2019-04-23T00:02:48.587335Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Match CPS microdata files with their data dictionary\n",
    "Matcher = {}\n",
    "\n",
    "DataDict.pop('matcher', None)\n",
    "for dfile, dvals in DataDict.items():\n",
    "    #print(dfile)\n",
    "    ddf = open(f'{dfile}', 'r', encoding='iso-8859-1').read()\n",
    "    if dfile in ['jan03dd.txt', 'augnov05dd.txt', 'jan07dd.txt']:\n",
    "        ddf = ddf.replace('PRNMCHLD', 'PRNMCHLD  2  ')\n",
    "    if dfile in ['jan98dd.asc', 'jan98dd2.asc']:\n",
    "        d = {text_repl(s[0]): [int(s[2])-1, int(s[2])+int(s[1])-1, int(s[1])] \n",
    "             for s in re.findall(dvals['re'], ddf) if s[0] in VarList}       \n",
    "    elif dfile == 'may04dd.txt':\n",
    "        d = {text_repl(s[0]): [int(s[2])-1, int(s[3]), int(s[1])] \n",
    "             for s in re.findall(\n",
    "                 dvals['re'].replace('(partII)', '\\(partII\\)'), ddf)}\n",
    "    else:\n",
    "        d = {text_repl(s[0]): [int(s[3])-1, int(s[4]), int(s[2])] \n",
    "             for s in re.findall(dvals['re'], ddf)}\n",
    "    \n",
    "    # Suggest dtypes for numpy\n",
    "    for k, v in d.items(): \n",
    "        d[k].append('U4' if k in ['HRSAMPLE']\n",
    "                    else 'U2' if k in ['HRSERSUF']\n",
    "                    else 'int32' if k in ['GTCO', 'GESTFIPS']\n",
    "                    #else 'int64' if k in ['HRHHID2']\n",
    "                    else 'f4' if 'WGT' in k\n",
    "                    else 'int8' if v[-1] < 3 \n",
    "                    else 'int16' if v[-1] < 5 \n",
    "                    else 'int32' if v[-1] < 11 \n",
    "                    else 'intp')    \n",
    "    \n",
    "    # Make sure that start and end = length\n",
    "    error_list = [k for k, v in d.items() if v[1] - v[0] != v[2]]\n",
    "    if len(error_list) > 0:\n",
    "        print(f'Error: {dfile}: {\", \".join(error_list)}')\n",
    "    DataDict[dfile]['dd'] = d\n",
    "    \n",
    "    # Add list of related monthly CPS microdata files\n",
    "    mos = pd.date_range(dvals['start'], dvals['end'], freq='MS')\n",
    "    monthly_file_list = [f'{i:%b%y}pub.dat'.lower() for i in mos]\n",
    "    DataDict[dfile]['flist'] = monthly_file_list\n",
    "    \n",
    "    # Add relevant monthly CPS filenames to matcher\n",
    "    for file in monthly_file_list:\n",
    "        Matcher[file] = dfile\n",
    "    \n",
    "    # Stuct unpack format\n",
    "    start, end, width, fmt = zip(*d.values())\n",
    "    skip = ([f'{st - en}x' if (st - en) > 0 else '' \n",
    "             for st, en in zip(start, [0] + list(end[:-1]))])\n",
    "    keep = [f'{w}s' for w in width]\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, keep) for j in i])\n",
    "    DataDict[dfile]['unpack_fmt'] = unpack_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T00:02:48.695609Z",
     "start_time": "2019-04-23T00:02:48.666047Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Create new/cleaned variables\n",
    "# Education groups\n",
    "educ = {'LTHS': [31, 32, 33, 34, 35, 36, 37, 38], \n",
    "        'HS': [39],\n",
    "        'SC': [40, 41, 42],\n",
    "        'COLL': [43],\n",
    "        'ADV': [44, 45, 46]}\n",
    "educ_map = {}\n",
    "for k, v in educ.items():\n",
    "    for i in v:\n",
    "        educ_map.update({i:k})\n",
    "\n",
    "for dfile, dvals in DataDict.items():\n",
    "    DataDict[dfile]['map'] = {}\n",
    "    \n",
    "    # Add state id map to two letter codes\n",
    "    DataDict[dfile]['map']['state'] = StatesMap\n",
    "    \n",
    "    # Add Census regions map from state two letter codes\n",
    "    DataDict[dfile]['map']['region'] = RegionsMap\n",
    "    \n",
    "    # Add education groups\n",
    "    DataDict[dfile]['map']['educ'] = educ_map\n",
    "    \n",
    "    # WBHAO and WBHAOM race/ethnic groups from CEPR\n",
    "    start_month = pd.to_datetime(dvals['start'])\n",
    "    if start_month > pd.to_datetime('2012-04-01'):\n",
    "        race = {'White': [1], \n",
    "                'Black': [2, 6, 10, 11, 12, 16, 17, 18, 22, 23], \n",
    "                'Asian': [4, 5, 8, 9, 13, 14, 15, 19, 20, 21, 24], \n",
    "                'Other': [3, 7, 25, 26]}\n",
    "        racem = {'White': [1],\n",
    "                 'Black': [2],\n",
    "                 'Asian': [4, 5],\n",
    "                 'Native American': [3],\n",
    "                 'Mixed': list(range(6, 27))}\n",
    "    elif start_month > pd.to_datetime('2002-12-01'):\n",
    "        race = {'White': [1], \n",
    "                'Black': [2, 6, 10, 11, 12, 15, 16, 19], \n",
    "                'Asian': [4, 5, 8, 9, 13, 14, 17, 18], \n",
    "                'Other': [3, 7, 20, 21]}\n",
    "        racem = {'White': [1],\n",
    "                 'Black': [2],\n",
    "                 'Asian': [4, 5],\n",
    "                 'Native American': [3],\n",
    "                 'Mixed': list(range(6, 22))}\n",
    "    else:  # Mixed not available before 2003\n",
    "        race = {'White': [1], \n",
    "                'Black': [2], \n",
    "                'Asian': [4], \n",
    "                'Other': [3, 5]}\n",
    "    race_map = {i: k for k, v in race.items() for i in v}\n",
    "    race_map2 = {i: k for k, v in racem.items() for i in v}\n",
    "    DataDict[dfile]['map']['race'] = race_map\n",
    "    DataDict[dfile]['map']['racem'] = race_map2    \n",
    "    \n",
    "    # Hispanic identification\n",
    "    if start_month > pd.to_datetime('2013-12-01'):\n",
    "        hisp = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    elif start_month > pd.to_datetime('2002-12-01'):\n",
    "        hisp = [1, 2, 3, 4, 5]\n",
    "    else:\n",
    "        hisp = [1, 2, 3, 4, 5, 6, 7]\n",
    "        \n",
    "    DataDict[dfile]['map']['hisp'] = hisp\n",
    "    \n",
    "    # Major industry group\n",
    "    start_month = pd.to_datetime(dvals['start'])\n",
    "    if start_month > pd.to_datetime('2002-12-01'):\n",
    "        ind = {'Construction and mining': [1, 2, 3],\n",
    "               'Finance and business services': [7, 8, 9, 12],\n",
    "               'Manufacturing': [4],\n",
    "               'Trade, transportation, and utilities': [5, 6],\n",
    "               'Education and health': [10],\n",
    "               'Leisure and hospitality': [11],\n",
    "               'Public administration': [13],\n",
    "               'Armed forces': [14]}\n",
    "    else:\n",
    "        ind = {'Construction and mining': [1, 2, 3, 21],\n",
    "               'Finance and business services': [7, 11, 12, 13, 14, 20],\n",
    "               'Manufacturing': [4, 5],\n",
    "               'Trade, transportation, and utilities': [6, 8, 9, 10],\n",
    "               'Education and health': [16, 17, 18, 19],\n",
    "               'Leisure and hospitality': [15],\n",
    "               'Public administration': [22],\n",
    "               'Armed forces': [23]}    \n",
    "    ind_map = {}\n",
    "    for k, v in ind.items():\n",
    "        for i in v:\n",
    "            ind_map[i] = k\n",
    "    DataDict[dfile]['map']['ind'] = ind_map        \n",
    "        \n",
    "    # Identify when to calculate ID2 manually\n",
    "    DataDict[dfile]['map']['id2'] = False\n",
    "    if start_month < pd.to_datetime('2004-05-01'):\n",
    "        DataDict[dfile]['map']['id2'] = True\n",
    "\n",
    "    # Identify weight variables for each data dict\n",
    "    wgt_vars = [i for i in dvals['dd'].keys() if 'WGT' in i]\n",
    "    DataDict[dfile]['map']['wgt'] = wgt_vars\n",
    "\n",
    "    # Identify earnings variables for each data dict\n",
    "    er_vars = [i for i in dvals['dd'].keys() if 'PRER' in i]\n",
    "    DataDict[dfile]['map']['er'] = er_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T00:02:48.703748Z",
     "start_time": "2019-04-23T00:02:48.697310Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate pickle file with data for reader\n",
    "DataDict['matcher'] = Matcher\n",
    "\n",
    "with open('cps_basic_dd.pkl', 'wb') as f:\n",
    "    pickle.dump(DataDict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
