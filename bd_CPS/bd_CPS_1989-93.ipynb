{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS extract\n",
    "\n",
    "bd_CPS_1989-93.ipynb\n",
    "\n",
    "April 16, 2019\n",
    "\n",
    "Contact: Brian Dew, @bd_econ\n",
    "\n",
    "----\n",
    "\n",
    "### About\n",
    "\n",
    "**Goal:** Use python to work with Current Population Survey data from 1989-93.\n",
    "\n",
    "This notebook reads raw CPS data from Census, downloaded from [NBER](https://www.nber.org/data/cps_basic.html), to generate annual feather-format files that match with the bd CPS extracts for 1994-onward. A major revision to the CPS in 1994 makes it impossible to completely match the 1989-93 data to the 1994-onward data, but this notebook attempts to adjust the 1989-93 data to match with 1994-onward data as close as possible. \n",
    "\n",
    "See the [GitHub repo page](https://github.com/bdecon/econ_data/tree/master/bd_CPS) for details on how to use the bd CPS and on what variables are available and how they are defined. See also the [benchmark notebook](https://github.com/bdecon/econ_data/blob/master/micro/bd_CPS_benchmark.ipynb) for examples of using the 1989-93 data. \n",
    "\n",
    "-----\n",
    "\n",
    "See [issues](https://github.com/bdecon/econ_data/issues?q=is%3Aopen+is%3Aissue+label%3A1989-93) and [project](https://github.com/bdecon/econ_data/projects/4) on Github. Please feel free to contact me if you have any questions or are interested in helping with the project. My email address is brianwdew@gmail.com.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "See this [discussion of the CPS revamp](https://www.bls.gov/cps/revisions1994.pdf) for guidance on matching the 1989-93 data to the 1994-onward data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:44:23.749237Z",
     "start_time": "2020-12-14T09:44:23.148019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.1.3\n",
      "numpy: 1.19.2\n"
     ]
    }
   ],
   "source": [
    "import os, re, struct, pickle, shutil\n",
    "import pandas as pd\n",
    "print('pandas:', pd.__version__)\n",
    "import numpy as np\n",
    "print('numpy:', np.__version__)\n",
    "\n",
    "data_dir = '/home/brian/Documents/CPS/data/'\n",
    "\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Data dictionary file generated by bd_CPS_dd.ipynb\n",
    "cpsdd = pickle.load(open('cps_basic_dd.pkl', 'rb'))\n",
    "\n",
    "# Dictionary of unique IDS\n",
    "ids_file = 'CPSID_89-93.pkl'\n",
    "if os.path.isfile(ids_file):\n",
    "    cps_ids_full = pickle.load(open(ids_file, 'rb'))\n",
    "    \n",
    "# Map codes for country of birth to country/area names\n",
    "from bd_CPS_details import EducDTMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:44:23.758039Z",
     "start_time": "2020-12-14T09:44:23.750322Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# If running for first time, unzip the annual NBER zip files in raw data \n",
    "# folder and run this block of code. It will rename the files accordingly.\n",
    "\n",
    "# Check if files exist:\n",
    "date_range = [dt.strftime('%b%y').lower() for dt in \n",
    "              pd.date_range(start='1989-01-01', end='1993-12-01', freq='MS')]\n",
    "correct_files = [f'{date}pub.dat' for date in date_range]\n",
    "if correct_files not in os.listdir():\n",
    "    # Rename unzipped NBER files\n",
    "    raw_files = [f for f in os.listdir() if f.startswith('cpsb') \n",
    "                 and '.dat' not in f and '.zip' not in f]\n",
    "    to_rename = list(set(raw_files) - set(correct_files))\n",
    "    for file in to_rename:\n",
    "        date = pd.to_datetime(f'19{file[4:6]}-{file[6:8]}-01')\n",
    "        os.rename(file, date.strftime('%b%y').lower() + 'pub.dat')\n",
    "        print('Renamed: ', file, date.strftime('%b%y').lower() + 'pub.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:44:23.767606Z",
     "start_time": "2020-12-14T09:44:23.759303Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# User-defined functions\n",
    "def id_dtype(size):\n",
    "    '''Return data type based on fixed-width size'''\n",
    "    size = int(size)\n",
    "    dtype = ('intp' if size > 9 \n",
    "             else 'int32' if size > 4 \n",
    "             else 'int16' if size > 2 \n",
    "             else 'int8')\n",
    "    return dtype\n",
    "\n",
    "def data_dict_reader(dd_file, var_list):\n",
    "    '''Read data dictionary and return variable locations'''\n",
    "    data_dict = open(dd_file, 'r', encoding='iso-8859-1').read()\n",
    "    p = ('(\\w{1,2}[\\$\\-%]\\w*|PADDING)\\s'\n",
    "         '*CHARACTER\\*(\\d{3})\\s*\\.{0,1}\\s*\\((\\d*):(\\d*)\\).*')\n",
    "    d = {s[0]: [int(s[2])-1, int(s[3]), f'{int(s[1])}s', id_dtype(s[1])]\n",
    "         for s in re.findall(p, data_dict) if s[0] in var_list}\n",
    "    return d\n",
    "\n",
    "def struct_unpacker(d):\n",
    "    '''Return struct unpacker from variable locations'''\n",
    "    start, end, width, size = zip(*d.values())\n",
    "    skip = ([f'{s - e}x' for s, e in zip(start, [0] + list(end[:-1]))])\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, width) for j in i])\n",
    "    return struct.Struct(unpack_fmt).unpack_from\n",
    "\n",
    "def data_file_reader(file, unpacker, dtypes, wgt):\n",
    "    '''Convert raw monthly file to pandas dataframe'''\n",
    "    raw_data = open(file, 'rb')\n",
    "    data = [unpacker(row) for row in raw_data if len(row) >= 405]\n",
    "    data = [tuple(int(i) if i.strip() else -1 for i in row) for row in data]\n",
    "    np_data = np.array(data, dtype=dtypes)\n",
    "    df = pd.DataFrame(np_data[np_data[wgt] > 0])\n",
    "    return df\n",
    "\n",
    "def kids_counter(df):\n",
    "    '''Count number of own kids under 5 and under 18'''\n",
    "    kids = (df.query('AGE < 18 and PARENT > 0')\n",
    "              .groupby(['HHID', 'STATE', 'PARENT']).PULINENO.count()\n",
    "              .reset_index()\n",
    "              .rename({'PARENT': 'PULINENO', \n",
    "                       'PULINENO': 'NUMCHILD1'}, axis=1))\n",
    "    result = (df.merge(kids, 'left')\n",
    "                .merge(kids.rename({'PULINENO': 'SPOUSE', \n",
    "                                    'NUMCHILD1': 'NUMCHILD2'}, axis=1), 'left'))\n",
    "    df['NCHILDU18'] = (np.where(result['NUMCHILD1'] > 0, result['NUMCHILD1'],\n",
    "                       np.where(result['NUMCHILD2'] > 0, result['NUMCHILD2'], 0))\n",
    "                         .astype('int8'))\n",
    "    kids = (df.query('AGE < 5 and PARENT > 0')\n",
    "              .groupby(['HHID', 'STATE', 'PARENT']).PULINENO.count()\n",
    "              .reset_index()\n",
    "              .rename({'PARENT': 'PULINENO', \n",
    "                       'PULINENO': 'NUMCHILD1'}, axis=1))\n",
    "    result2 = (df.merge(kids, 'left')\n",
    "                 .merge(kids.rename({'PULINENO': 'SPOUSE', \n",
    "                                     'NUMCHILD1': 'NUMCHILD2'}, axis=1), 'left'))\n",
    "    df['NCHILDU5'] = (np.where(result2['NUMCHILD1'] > 0, result2['NUMCHILD1'],\n",
    "                      np.where(result2['NUMCHILD2'] > 0, result2['NUMCHILD2'], 0))\n",
    "                        .astype('int8'))\n",
    "    df = df.drop(['PARENT', 'SPOUSE'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:46:14.469713Z",
     "start_time": "2020-12-14T09:44:23.768722Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989 Done: (1,713,347 records, 52 variables, 170.0MB)\n",
      "1990 Done: (1,791,585 records, 52 variables, 177.8MB)\n",
      "1991 Done: (1,774,232 records, 52 variables, 176.0MB)\n",
      "1992 Done: (1,746,184 records, 53 variables, 186.6MB)\n",
      "1993 Done: (1,722,398 records, 53 variables, 184.0MB)\n"
     ]
    }
   ],
   "source": [
    "# Create annual feather files\n",
    "dd_files = {'cps89.ddf': [1989, 1990, 1991],\n",
    "            'cps92.ddf': [1992, 1993]}\n",
    "\n",
    "var_list = ['H-MONTH', 'H-YEAR', 'H-MIS', 'HG-FIPS', 'H-METSTA', 'A-VET',\n",
    "            'H-ID', 'A-LINENO', 'A-AGE', 'A-MARITL', 'A-SEX', 'A-HGA',\n",
    "            'A-RACE', 'A-IND', 'A-OCC', 'A-CLSWKR', 'HG-MSAC', 'HG-CMSA',\n",
    "            'A-USLHRS', 'A-UNMEM', 'A-REORGN', 'A-LFSR', 'A-ENRLW',\n",
    "            'A-UNTYPE', 'A-FNLWGT', 'A-ERNLWT', 'A-HRLYWK', 'H-HHWGT',\n",
    "            'A-HERNTP', 'A-WERNTP', 'A-HRS1', 'A-WKSLK', 'H-HHNUM',\n",
    "            'A-UNCOV', 'A-HGC', 'A-MJIND', 'A-MJOCC', 'A-WKSTAT', \n",
    "            'A-DTOCC', 'A-DTIND', 'A-SPOUSE', 'A-PARENT', 'A-EMPHRS',\n",
    "            'H-HTYPE', '']\n",
    "\n",
    "# Remove the first two characters from each variable name\n",
    "rename_list = {v: v[2:] for v in var_list if v[0:2] != 'HG'}\n",
    "rename_list['HG-FIPS'] = 'STATEFIPS'\n",
    "rename_list['A-WKSLK'] = 'UNEMPDUR'\n",
    "rename_list['HG-MSAC'] = 'MSA'\n",
    "rename_list['HG-CMSA'] = 'CMSA'\n",
    "filter_wgt = 'A-FNLWGT'\n",
    "\n",
    "# Map state FIPS codes to two letter codes\n",
    "state_codes = cpsdd['jan94_mar94_dd.txt']['map']['state']\n",
    "region_codes = cpsdd['jan94_mar94_dd.txt']['map']['region']\n",
    "state = lambda x: pd.Categorical(x['STATEFIPS'].map(state_codes))\n",
    "region = lambda x: x['STATE'].map(region_codes)\n",
    "\n",
    "# 1992-onward educ codes\n",
    "educ_codes = cpsdd['jan94_mar94_dd.txt']['map']['educ']\n",
    "educ = lambda x: x['HGA'].map(educ_codes)\n",
    "educdt = lambda x: x['HGA'].map(EducDTMap)\n",
    "\n",
    "# School enrollment\n",
    "schenr = lambda x: pd.Categorical(\n",
    "    np.where(x['ENRLW'] == 1, 1, \n",
    "    np.where(x['ENRLW'] == 2, 0, np.nan)))\n",
    "\n",
    "# major industry group\n",
    "ind_codes = cpsdd['jan94_mar94_dd.txt']['map']['ind']\n",
    "indgrp =  lambda x: pd.Categorical(x['MJIND'].map(ind_codes))\n",
    "\n",
    "# Unemployment type recode - FIX (MAP IS SLOW)\n",
    "unemptype_map = {1: 'Job Loser', 2: 'Job Loser',\n",
    "                 3: 'Job Leaver',\n",
    "                 4: 'Re-entrant',\n",
    "                 5: 'New Entrant'}\n",
    "\n",
    "unemptype = lambda x: x['UNTYPE'].map(unemptype_map)\n",
    "\n",
    "# Layoff vs looking\n",
    "layoff = lambda x: pd.Categorical(\n",
    "    np.where(x['LFSR'] == 4, 'Layoff',\n",
    "    np.where(x['LFSR'] == 3, 'Looking', np.nan)))\n",
    "\n",
    "# Part-time for economic reasons\n",
    "ptecon = lambda x: pd.Categorical(\n",
    "    np.where(x['WKSTAT'].isin([3, 5]), 1, \n",
    "    np.where(x['WKSTAT'].between(2, 5), 0, np.nan)))\n",
    "\n",
    "# Worked full-time (usually FT or usually PT)\n",
    "workft = lambda x: pd.Categorical(\n",
    "    np.where(x['WKSTAT'] == 2, 1,\n",
    "    np.where(x['WKSTAT'].between(2, 5), 0, np.nan)))\n",
    "\n",
    "# Worked full-time (usually FT or usually PT)\n",
    "notatwork = lambda x: pd.Categorical(\n",
    "    np.where(x['EMPHRS'].isin([1, 2, 3, 4, 5]), 1,\n",
    "    np.where(x['EMPHRS'].between(6, 16), 0, np.nan)))\n",
    "\n",
    "# Map WBHAO codes for race/ethnicity\n",
    "hisp_map = cpsdd['jan94_mar94_dd.txt']['map']['hisp']\n",
    "hispanic = lambda x: pd.Categorical(np.where(x['REORGN'].isin(hisp_map), 1, 0))\n",
    "race_map = cpsdd['jan94_mar94_dd.txt']['map']['race']\n",
    "wbhao = lambda x: (    # If not hispanic, map race to racial groups\n",
    "    pd.Categorical(np.where(x['REORGN'].isin(hisp_map), 'Hispanic', \n",
    "                            x['RACE'].map(race_map))))\n",
    "wbao = lambda x: pd.Categorical(x['RACE'].map(race_map))\n",
    "\n",
    "# Wage variables\n",
    "wkwage = lambda x: np.where(x['WERNTP'] > 0, x['WERNTP'], np.nan)\n",
    "hrwage = lambda x: np.where((x['HERNTP'] < 0) & (x['USLHRS'] > 0 ) & \n",
    "                            (x['WERNTP'] > 0), x['WERNTP'] / x['USLHRS'], \n",
    "                            np.where(x['HERNTP'] > 0, x['HERNTP'] / 100.0, \n",
    "                                     np.nan)) \n",
    "rhrwage = lambda x: (\n",
    "    np.where(x['HRWAGE'] > 0, x['HRWAGE'] * x['REGION'].map(cpi_vals), np.nan))\n",
    "rwkwage = lambda x: (\n",
    "    np.where(x['WKWAGE'] > 0, x['WKWAGE'] * x['REGION'].map(cpi_vals), np.nan))\n",
    "\n",
    "# Union member and coverage\n",
    "union = lambda x: pd.Categorical(\n",
    "    np.where((x['UNMEM'] == 1) | (x['UNCOV'] == 1), 1, \n",
    "    np.where((x['UNMEM'] == 2) & (x['UNCOV'] == 2), 0, np.nan)),\n",
    "    ordered=True)\n",
    "unionmem = lambda x: pd.Categorical(\n",
    "    np.where(x['UNMEM'] == 1, 1, \n",
    "    np.where(x['UNMEM'] == 2, 0, np.nan)),\n",
    "    ordered=True)\n",
    "\n",
    "# Paid hourly\n",
    "paidhrly = lambda x: pd.Categorical(\n",
    "    np.where(x['HRLYWK'] == 1, 1,\n",
    "    np.where(x['HRLYWK'] == 2, 0, np.nan)))\n",
    "\n",
    "# bd CPS consistent variables\n",
    "age = lambda x: np.where(x['AGE'] > 80, 80, x['AGE'])\n",
    "female = lambda x: np.where(x['SEX'] == 2, 1, 0)\n",
    "veteran = lambda x: np.where(x['VET'].isin([1, 2, 3, 4, 5]), 1,\n",
    "                             np.where(x['VET'] == 6, 0, np.nan))\n",
    "married = lambda x: np.where(x['MARITL'].isin([1, 2, 3]), 1, \n",
    "                             np.where(x['MARITL'].isin([4,5,6,7]), 0, np.nan))\n",
    "emp = lambda x: np.where(x['LFSR'].isin([1,2]), 1, 0)\n",
    "\n",
    "# Labor force status\n",
    "lfs = lambda x: pd.Categorical(\n",
    "    np.where(x['LFSR'].isin([1, 2]), 'Employed',\n",
    "    np.where(x['LFSR'].isin([3, 4]), 'Unemployed',\n",
    "    np.where(x['LFSR'].isin([5, 6, 7]), 'NILF', np.nan))))\n",
    "\n",
    "# Class of worker\n",
    "cow1 = lambda x: pd.Categorical(\n",
    "    np.where(x['CLSWKR'] == 2, 'Federal Government',\n",
    "    np.where(x['CLSWKR'] == 3, 'State Government',\n",
    "    np.where(x['CLSWKR'] == 4, 'Local Government',\n",
    "    np.where(x['CLSWKR'] == 1, 'Private',\n",
    "    np.where(x['CLSWKR'] == 5, 'Self-employed Incorporated',\n",
    "    np.where(x['CLSWKR'] == 6, 'Self-employed Unincorporated',\n",
    "    np.where(x['CLSWKR'] == 7, 'Without Pay', np.nan))))))))\n",
    "\n",
    "\n",
    "# Weight variables\n",
    "basicwgt = lambda x: np.where(x['FNLWGT'] > 0, x['FNLWGT'] / 100.0, x['FNLWGT'])\n",
    "pworwgt = lambda x: np.where(x['ERNLWT'] > 0, x['ERNLWT'] / 100.0, x['ERNLWT'])\n",
    "hhwgt = lambda x: np.where(x['HHWGT'] > 0, x['HHWGT'] / 100.0, x['HHWGT'])\n",
    "\n",
    "# Read in Consumer Price Index data created by bd_CPS_cpi.ipynb\n",
    "cpi = pd.read_csv('clean/cpi.csv', index_col=[0], parse_dates=True)\n",
    "\n",
    "# Read data dictionaries for information on processing raw data files\n",
    "for ddf, year_list in dd_files.items():\n",
    "    \n",
    "    d = data_dict_reader(ddf, var_list)\n",
    "\n",
    "    dtypes = [(k, v[-1]) for k, v in d.items()]\n",
    "\n",
    "    unpacker = struct_unpacker(d)\n",
    "\n",
    "    # Loop over and process each monthly file in each year\n",
    "    for year in year_list:\n",
    "        file_list = [file for file in os.listdir()\n",
    "                     if file.endswith(f'{str(year)[2:]}pub.dat')]        \n",
    "        combined_data = []\n",
    "        \n",
    "        for file in file_list:\n",
    "            date = pd.to_datetime(f'{year}-{file[:3]}-01')\n",
    "            cpi_vals = cpi.loc[date].to_dict()\n",
    "            df = data_file_reader(file, unpacker, dtypes, filter_wgt)\n",
    "            df = df.rename(rename_list, axis=1)\n",
    "            # Education variable underlying data changes in 1992\n",
    "            if year < 1992:\n",
    "                educ_map = {\n",
    "                    'LTHS': (df['HGA'].between(1, 11)) | ((df['HGA']==12) & \n",
    "                                                          (df['HGC']==2)),\n",
    "                    'HS': (df['HGA']==12) & (df['HGC']==1),\n",
    "                    'SC': (df['HGA'].between(13,15)) | ((df['HGA']==16) & \n",
    "                                                        (df['HGC']==2)),\n",
    "                    'COLL': ((df['HGA']==16) & (df['HGC']==1)) | (df['HGA']==17),\n",
    "                    'ADV': (df['HGA'] >= 18)}\n",
    "                df['EDUC'] = (np.select(educ_map.values(), \n",
    "                                        educ_map.keys(), \n",
    "                                        default=None))\n",
    "                df = df.drop(['HGA', 'HGC'], axis=1)\n",
    "            # Add custom variables defined above\n",
    "            if year >= 1992:\n",
    "                df = df.assign(EDUC = educ, EDUCDT = educdt).drop(['HGA'], axis=1)\n",
    "            df = (df.assign(STATE = state,\n",
    "                            REGION = region,\n",
    "                            AGE = age,\n",
    "                            FEMALE = female,\n",
    "                            WBHAO = wbhao,\n",
    "                            WBAO = wbao,\n",
    "                            HISPANIC = hispanic,\n",
    "                            VETERAN = veteran,\n",
    "                            SCHENR = schenr,\n",
    "                            MARRIED = married,\n",
    "                            EMP = emp,\n",
    "                            LFS = lfs,\n",
    "                            COW1 = cow1,\n",
    "                            UNEMPTYPE = unemptype,\n",
    "                            LAYOFF = layoff,\n",
    "                            PTECON = ptecon,\n",
    "                            WORKFT = workft,\n",
    "                            NOTATWORK = notatwork,\n",
    "                            UNION = union,\n",
    "                            UNIONMEM = unionmem,\n",
    "                            PAIDHRLY = paidhrly,\n",
    "                            INDGRP = indgrp,\n",
    "                            WKWAGE = wkwage,\n",
    "                            HRWAGE = hrwage,\n",
    "                            RHRWAGE = rhrwage,\n",
    "                            RWKWAGE = rwkwage,\n",
    "                            BASICWGT = basicwgt,\n",
    "                            PWORWGT = pworwgt,\n",
    "                            HHWGT = hhwgt)\n",
    "                    .drop(['STATEFIPS', 'SEX', 'VET', 'MARITL', 'UNTYPE',\n",
    "                           'REORGN', 'ENRLW', 'WKSTAT', 'UNMEM', 'RACE',\n",
    "                           'UNCOV', 'CLSWKR', 'HRLYWK', 'HERNTP', 'EMP',\n",
    "                           'WERNTP', 'LFSR', 'FNLWGT', 'ERNLWT', 'EMPHRS'], axis=1))\n",
    "            df['YEAR'] = year\n",
    "            \n",
    "            # Rename and resize selected variables\n",
    "            df = df.rename({'USLHRS': 'HRSUSL1', 'HRS1': 'HRSACTT',\n",
    "                            'ID': 'HHID', 'LINENO': 'PULINENO',\n",
    "                            'DTIND': 'IND80D', 'DTOCC': 'OCC80D',\n",
    "                            'MJIND': 'IND80M', 'MJOCC': 'OCC80M',\n",
    "                            'IND': 'IND80', 'OCC': 'OCC80'}, axis=1)\n",
    "            resize_vars = ['STATE', 'FEMALE', 'VETERAN', 'MARRIED', \n",
    "                           'EDUC', 'UNEMPTYPE', 'REGION', 'YEAR', 'PTECON',\n",
    "                           'CMSA', 'MSA', 'HHNUM']\n",
    "            df[resize_vars] = df[resize_vars].astype('category')\n",
    "            flt_vars = ['WKWAGE', 'HRWAGE', 'RHRWAGE', 'RWKWAGE', \n",
    "                        'BASICWGT', 'PWORWGT']\n",
    "            df[flt_vars] = df[flt_vars].astype('float32')\n",
    "            #df = kids_counter(df)\n",
    "            \n",
    "            # Add QSTNUM and OCCURNUM\n",
    "            df['QSTNUM'] = df.groupby('HHID').ngroup().astype('int32')\n",
    "            df['OCCURNUM'] = ((df.groupby('QSTNUM').cumcount() + 1)\n",
    "                                 .astype('int8'))\n",
    "            \n",
    "            # bd CPS household ID\n",
    "            if os.path.isfile(ids_file):\n",
    "                df['CPSID'] = df['QSTNUM'].map(cps_ids_full[date])\n",
    "\n",
    "            combined_data.append(df)\n",
    "            \n",
    "        # Combine monthly files into annual file\n",
    "        df = (pd.concat(combined_data)).reset_index(drop=True)\n",
    "        \n",
    "        ind_occ_cats = ['INDGRP', 'IND80', 'OCC80', 'IND80D', 'OCC80D',\n",
    "                        'IND80M', 'OCC80M']\n",
    "        \n",
    "        df[ind_occ_cats] = df[ind_occ_cats].astype('category')        \n",
    "        \n",
    "        # Store results as feather file\n",
    "        df.to_feather(f'clean/cps{year}.ft')\n",
    "        \n",
    "        # Print outcome\n",
    "        obs = len(df)\n",
    "        cols = len(df.keys())\n",
    "        size = round(df.memory_usage().sum() / 1024**2, 1)\n",
    "        print(f'{year} Done: ({obs:,} records, {cols} variables, {size}MB)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
