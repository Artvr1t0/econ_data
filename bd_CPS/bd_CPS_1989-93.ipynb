{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS extract\n",
    "\n",
    "bd_CPS_revisions_reader.ipynb\n",
    "\n",
    "January 30, 2019\n",
    "\n",
    "Contact: Brian Dew, @bd_econ\n",
    "\n",
    "-----\n",
    "\n",
    "See [issues](https://github.com/bdecon/econ_data/issues?q=is%3Aopen+is%3Aissue+label%3A1989-93) and [project](https://github.com/bdecon/econ_data/projects/4) on Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:14:52.245977Z",
     "start_time": "2019-01-30T18:14:52.241831Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, re, struct, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('/home/brian/Documents/CPS/data/')\n",
    "\n",
    "cpsdd = pickle.load(open('cps_basic_dd.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:14:52.267007Z",
     "start_time": "2019-01-30T18:14:52.247598Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# User-defined functions\n",
    "def id_dtype(size):\n",
    "    '''Return data type based on fixed-width size'''\n",
    "    size = int(size)\n",
    "    dtype = ('intp' if size > 9 \n",
    "             else 'int32' if size > 4 \n",
    "             else 'int16' if size > 2 \n",
    "             else 'int8')\n",
    "    return dtype\n",
    "\n",
    "def data_dict_reader(dd_file, var_list):\n",
    "    '''Read data dictionary and return variable locations'''\n",
    "    data_dict = open(dd_file, 'r', encoding='iso-8859-1').read()\n",
    "    p = ('(\\w{1,2}[\\$\\-%]\\w*|PADDING)\\s'\n",
    "         '*CHARACTER\\*(\\d{3})\\s*\\.{0,1}\\s*\\((\\d*):(\\d*)\\).*')\n",
    "    d = {s[0]: [int(s[2])-1, int(s[3]), f'{int(s[1])}s', id_dtype(s[1])]\n",
    "         for s in re.findall(p, data_dict) if s[0] in var_list}\n",
    "    return d\n",
    "\n",
    "def struct_unpacker(d):\n",
    "    '''Return struct unpacker from variable locations'''\n",
    "    start, end, width, size = zip(*d.values())\n",
    "    skip = ([f'{s - e}x' for s, e in zip(start, [0] + list(end[:-1]))])\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, width) for j in i])\n",
    "    return struct.Struct(unpack_fmt).unpack_from\n",
    "\n",
    "def data_file_reader(file, unpacker, dtypes, wgt):\n",
    "    '''Convert raw monthly file to dataframe'''\n",
    "    raw_data = open(file, 'rb')\n",
    "    data = [unpacker(row) for row in raw_data if len(row) >= 405]\n",
    "    data = [tuple(int(i) if i.strip() else -1 for i in row) for row in data]\n",
    "    np_data = np.array(data, dtype=dtypes)\n",
    "    df = pd.DataFrame(np_data[np_data[wgt] > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T18:44:00.217643Z",
     "start_time": "2019-01-30T18:42:13.730491Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989 Done: (1,713,347 records, 40 variables)\n",
      "1990 Done: (1,791,585 records, 40 variables)\n",
      "1991 Done: (1,774,232 records, 40 variables)\n",
      "1992 Done: (1,746,184 records, 40 variables)\n",
      "1993 Done: (1,722,398 records, 40 variables)\n"
     ]
    }
   ],
   "source": [
    "# Create annual feather files\n",
    "dd_files = {'cps89.ddf': [1989, 1990, 1991],\n",
    "            'cps92.ddf': [1992, 1993]}\n",
    "\n",
    "var_list = ['H-MONTH', 'H-YEAR', 'H-MIS', 'HG-FIPS', 'H-METSTA', 'A-VET',\n",
    "            'H-ID', 'A-LINENO', 'A-AGE', 'A-MARITL', 'A-SEX', 'A-HGA',\n",
    "            'A-RACE', 'A-MAJACT', 'A-IND', 'A-OCC', 'A-USLFT', 'A-CLSWKR',\n",
    "            'A-USLHRS', 'A-UNMEM', 'A-FTPT', 'A-REORGN', 'A-LFSR', 'A-ENRLW',\n",
    "            'A-UNTYPE', 'A-NLFREA', 'A-RCOW', 'A-FNLWGT', 'A-ERNLWT',\n",
    "            'A-HERNTP', 'A-WERNTP', 'A-HRS1', 'A-WKSLK', 'A-WANTJB', \n",
    "            'A-UNCOV', 'A-HGC']\n",
    "\n",
    "# Remove the first two characters from each variable name\n",
    "rename_list = {v: v[2:] for v in var_list if v[0:2] != 'HG'}\n",
    "rename_list['HG-FIPS'] = 'STATEFIPS'\n",
    "rename_list['A-WKSLK'] = 'UNEMPDUR'\n",
    "filter_wgt = 'A-FNLWGT'\n",
    "\n",
    "# Map state FIPS codes to two letter codes\n",
    "state_codes = cpsdd['jan94_mar94_dd.txt']['map']['state']\n",
    "region_codes = cpsdd['jan94_mar94_dd.txt']['map']['region']\n",
    "state = lambda x: pd.Categorical(x['STATEFIPS'].map(state_codes))\n",
    "\n",
    "# 1992-onward educ codes\n",
    "educ_codes = cpsdd['jan94_mar94_dd.txt']['map']['educ']\n",
    "educ = lambda x: pd.Categorical(x['HGA'].map(educ_codes))\n",
    "\n",
    "# Unemployment type recode\n",
    "unemptype = lambda x: (\n",
    "    pd.Categorical(np.where(x['UNTYPE'].isin([1, 2]), 'Job Loser',\n",
    "                   np.where(x['UNTYPE'] == 3, 'Job Leaver',\n",
    "                   np.where(x['UNTYPE'] == 4, 'Re-entrant',\n",
    "                   np.where(x['UNTYPE'] == 5, 'New Entrant', np.nan))))))\n",
    "\n",
    "# Map WBHAO codes for race/ethnicity\n",
    "hisp_map = cpsdd['jan94_mar94_dd.txt']['map']['hisp']\n",
    "race_map = cpsdd['jan94_mar94_dd.txt']['map']['race']\n",
    "wbhao = lambda x: (    # If not hispanic, map race to racial groups\n",
    "    pd.Categorical(np.where(x['REORGN'].isin(hisp_map), 'Hispanic', \n",
    "                            x['RACE'].map(race_map))))\n",
    "\n",
    "# Wage variables\n",
    "wkwage = lambda x: np.where(x['WERNTP'] > 0, x['WERNTP'], np.nan)\n",
    "hrwage = lambda x: np.where((x['HERNTP'] < 0) & (x['USLHRS'] > 0 ) & \n",
    "                            (x['WERNTP'] > 0), x['WERNTP'] / x['USLHRS'], \n",
    "                            np.where(x['HERNTP'] > 0, x['HERNTP'] / 100.0, \n",
    "                                     np.nan)) \n",
    "rhrwage = lambda x: (\n",
    "    np.where(x['HRWAGE'] > 0, \n",
    "             x['HRWAGE'] * x['STATE'].map(region_codes).map(cpi_vals), \n",
    "             np.nan))\n",
    "rhrwage2 = lambda x: (\n",
    "    np.where(x['HRWAGE'] > 0, x['HRWAGE'] * cpi_vals['ALL'], np.nan))\n",
    "rwkwage = lambda x: (\n",
    "    np.where(x['WKWAGE'] > 0, \n",
    "             x['WKWAGE'] * x['STATE'].map(region_codes).map(cpi_vals), \n",
    "             np.nan))\n",
    "\n",
    "# bd CPS consistent variables\n",
    "female = lambda x: np.where(x['SEX'] == 2, 1, 0)\n",
    "veteran = lambda x: np.where(x['VET'].isin([1, 2, 3, 4, 5]), 1,\n",
    "                             np.where(x['VET'] == 6, 0, np.nan))\n",
    "married = lambda x: np.where(x['MARITL'].isin([1, 2, 3]), 1, \n",
    "                             np.where(x['MARITL'].isin([4,5,6,7]), 0, np.nan))\n",
    "emp = lambda x: np.where(x['LFSR'].isin([1,2]), 1, 0)\n",
    "\n",
    "\n",
    "cpi = pd.read_csv('clean/cpi.csv', index_col=[0], parse_dates=True)\n",
    "for ddf, year_list in dd_files.items():\n",
    "    \n",
    "    d = data_dict_reader(ddf, var_list)\n",
    "\n",
    "    dtypes = [(k, v[-1]) for k, v in d.items()]\n",
    "\n",
    "    unpacker = struct_unpacker(d)\n",
    "\n",
    "    for year in year_list:\n",
    "        file_list = [f for f in os.listdir() \n",
    "                    if f.startswith((f'cpsb{str(year)[2:]}')) \n",
    "                    and f.endswith('.dat')]\n",
    "        combined_data = []\n",
    "        \n",
    "        for file in file_list:\n",
    "            date = pd.to_datetime(f'{year}-{file[6:8]}-01')\n",
    "            cpi_vals = cpi.loc[date].to_dict()\n",
    "            df = data_file_reader(file, unpacker, dtypes, filter_wgt)\n",
    "\n",
    "            decimal_vars = ['A-FNLWGT', 'A-ERNLWT']\n",
    "            df[decimal_vars] = df[decimal_vars] / 100.0\n",
    "            df = df.rename(rename_list, axis=1)\n",
    "            if year < 1992:\n",
    "                educ_map = {\n",
    "                    'LTHS': (df['HGA'].between(1, 11)) | ((df['HGA']==12) & \n",
    "                                                          (df['HGC']==2)),\n",
    "                    'HS': (df['HGA']==12) & (df['HGC']==1),\n",
    "                    'SC': (df['HGA'].between(13,15)) | ((df['HGA']==16) & \n",
    "                                                        (df['HGC']==2)),\n",
    "                    'COLL': ((df['HGA']==16) & (df['HGC']==1)) | (df['HGA']==17),\n",
    "                    'ADV': (df['HGA'] >= 18)}\n",
    "                df['EDUC'] = np.select(educ_map.values(), educ_map.keys(), default=None)\n",
    "                df = df.drop(['HGA', 'HGC'], axis=1)\n",
    "            if year >= 1992:\n",
    "                df = df.assign(EDUC = educ).drop(['HGA'], axis=1)\n",
    "            df = (df.assign(STATE = state,\n",
    "                            FEMALE = female,\n",
    "                            WBHAO = wbhao,\n",
    "                            VETERAN = veteran,\n",
    "                            MARRIED = married,\n",
    "                            EMP = emp,\n",
    "                            UNEMPTYPE = unemptype,\n",
    "                            WKWAGE = wkwage,\n",
    "                            HRWAGE = hrwage,\n",
    "                            RHRWAGE = rhrwage,\n",
    "                            RHRWAGE2 = rhrwage2,\n",
    "                            RWKWAGE = rwkwage)\n",
    "                    .drop(['STATEFIPS', 'SEX', 'VET', 'MARITL', 'UNTYPE',\n",
    "                           'RACE', 'REORGN'], axis=1))\n",
    "            df['YEAR'] = year\n",
    "            df = df.assign(YEAR = lambda x: pd.Categorical(x['YEAR']))\n",
    "            df = df.rename({'FNLWGT': 'BASICWGT', 'ERNLWT': 'PWORWGT'}, axis=1)\n",
    "            resize_vars = ['STATE', 'FEMALE', 'VETERAN', 'MARRIED', 'EMP', 'EDUC']\n",
    "            df[resize_vars] = df[resize_vars].astype('category')\n",
    "\n",
    "            combined_data.append(df)\n",
    "        df = (pd.concat(combined_data))\n",
    "        \n",
    "        df.reset_index(drop=True).to_feather(f'clean/cps{year}.ft')\n",
    "        print(f'{year} Done: ({len(df):,} records, {len(df.keys())} variables)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
