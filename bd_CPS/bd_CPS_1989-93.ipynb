{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS extract\n",
    "\n",
    "bd_CPS_1989-93.ipynb\n",
    "\n",
    "April 16, 2019\n",
    "\n",
    "Contact: Brian Dew, @bd_econ\n",
    "\n",
    "----\n",
    "\n",
    "### About\n",
    "\n",
    "**Goal:** Use python to work with Current Population Survey data from 1989-93.\n",
    "\n",
    "This notebook reads raw CPS data from Census, downloaded from [NBER](https://www.nber.org/data/cps_basic.html), to generate annual feather-format files that match with the bd CPS extracts for 1994-onward. A major revision to the CPS in 1994 makes it impossible to completely match the 1989-93 data to the 1994-onward data, but this notebook attempts to adjust the 1989-93 data to match with 1994-onward data as close as possible. \n",
    "\n",
    "See the [GitHub repo page](https://github.com/bdecon/econ_data/tree/master/bd_CPS) for details on how to use the bd CPS and on what variables are available and how they are defined. See also the [benchmark notebook](https://github.com/bdecon/econ_data/blob/master/micro/bd_CPS_benchmark.ipynb) for examples of using the 1989-93 data. \n",
    "\n",
    "-----\n",
    "\n",
    "See [issues](https://github.com/bdecon/econ_data/issues?q=is%3Aopen+is%3Aissue+label%3A1989-93) and [project](https://github.com/bdecon/econ_data/projects/4) on Github. Please feel free to contact me if you have any questions or are interested in helping with the project. My email address is brianwdew@gmail.com.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "See this [discussion of the CPS revamp](https://www.bls.gov/cps/revisions1994.pdf) for guidance on matching the 1989-93 data to the 1994-onward data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T16:00:36.762082Z",
     "start_time": "2021-08-11T16:00:36.060102Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.2.4\n",
      "numpy: 1.20.2\n"
     ]
    }
   ],
   "source": [
    "# import libraries and settings\n",
    "import os, re, struct, pickle, shutil\n",
    "import pandas as pd\n",
    "print('pandas:', pd.__version__)\n",
    "import numpy as np\n",
    "print('numpy:', np.__version__)\n",
    "\n",
    "data_dir = '/home/brian/Documents/CPS/data/'\n",
    "\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Data dictionary file generated by bd_CPS_dd.ipynb\n",
    "cpsdd = pickle.load(open('cps_basic_dd.pkl', 'rb'))\n",
    "\n",
    "# Dictionary of unique IDS\n",
    "ids_file = 'CPSID_89-93.pkl'\n",
    "if os.path.isfile(ids_file):\n",
    "    cps_ids_full = pickle.load(open(ids_file, 'rb'))\n",
    "    \n",
    "# Map codes for country of birth to country/area names\n",
    "from bd_CPS_details import EducDTMap, INDMMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T16:00:36.827335Z",
     "start_time": "2021-08-11T16:00:36.763188Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "month must be in 1..12: 1919-88-01",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36m_build_naive\u001b[0;34m(self, res, default)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m         \u001b[0mnaive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: month must be in 1..12",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParserError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: month must be in 1..12: 1919-88-01",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid string coercion to datetime",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36m_build_naive\u001b[0;34m(self, res, default)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m         \u001b[0mnaive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: month must be in 1..12",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-66e26e9bb66b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mto_rename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_rename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'19{file[4:6]}-{file[6:8]}-01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%b%y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'pub.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Renamed: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%b%y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'pub.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mutc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"utc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object)\u001b[0m\n\u001b[1;32m   2088\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz_parsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2090\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtz_parsed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object)\u001b[0m\n\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2075\u001b[0;31m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[1;32m   2076\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime_object\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime_object\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/dateutil/parser/_parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_naive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParserError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignoretz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: month must be in 1..12: 1919-88-01"
     ]
    }
   ],
   "source": [
    "# If running for first time, unzip the annual NBER zip files in raw data \n",
    "# folder and run this block of code. It will rename the files accordingly.\n",
    "\n",
    "# Check if files exist:\n",
    "date_range = [dt.strftime('%b%y').lower() for dt in \n",
    "              pd.date_range(start='1989-01-01', end='1993-12-01', freq='MS')]\n",
    "correct_files = [f'{date}pub.dat' for date in date_range]\n",
    "if correct_files not in os.listdir():\n",
    "    # Rename unzipped NBER files\n",
    "    raw_files = [f for f in os.listdir() if f.startswith('cpsb') \n",
    "                 and '.dat' not in f and '.zip' not in f]\n",
    "    to_rename = list(set(raw_files) - set(correct_files))\n",
    "    for file in to_rename:\n",
    "        date = pd.to_datetime(f'19{file[4:6]}-{file[6:8]}-01')\n",
    "        os.rename(file, date.strftime('%b%y').lower() + 'pub.dat')\n",
    "        print('Renamed: ', file, date.strftime('%b%y').lower() + 'pub.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T16:00:36.828470Z",
     "start_time": "2021-08-11T16:00:36.064Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# User-defined functions\n",
    "def id_dtype(size):\n",
    "    '''Return data type based on fixed-width size'''\n",
    "    size = int(size)\n",
    "    dtype = ('intp' if size > 9 \n",
    "             else 'int32' if size > 4 \n",
    "             else 'int16' if size > 2 \n",
    "             else 'int8')\n",
    "    return dtype\n",
    "\n",
    "def data_dict_reader(dd_file, var_list):\n",
    "    '''Read data dictionary and return variable locations'''\n",
    "    data_dict = open(dd_file, 'r', encoding='iso-8859-1').read()\n",
    "    p = ('(\\w{1,2}[\\$\\-%]\\w*|PADDING)\\s'\n",
    "         '*CHARACTER\\*(\\d{3})\\s*\\.{0,1}\\s*\\((\\d*):(\\d*)\\).*')\n",
    "    d = {s[0]: [int(s[2])-1, int(s[3]), f'{int(s[1])}s', id_dtype(s[1])]\n",
    "         for s in re.findall(p, data_dict) if s[0] in var_list}\n",
    "    return d\n",
    "\n",
    "def struct_unpacker(d):\n",
    "    '''Return struct unpacker from variable locations'''\n",
    "    start, end, width, size = zip(*d.values())\n",
    "    skip = ([f'{s - e}x' for s, e in zip(start, [0] + list(end[:-1]))])\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, width) for j in i])\n",
    "    return struct.Struct(unpack_fmt).unpack_from\n",
    "\n",
    "def data_file_reader(file, unpacker, dtypes, wgt):\n",
    "    '''Convert raw monthly file to pandas dataframe'''\n",
    "    raw_data = open(file, 'rb')\n",
    "    data = [unpacker(row) for row in raw_data if len(row) >= 405]\n",
    "    data = [tuple(int(i) if i.strip() else -1 for i in row) for row in data]\n",
    "    np_data = np.array(data, dtype=dtypes)\n",
    "    df = pd.DataFrame(np_data[np_data[wgt] > 0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T16:00:36.829242Z",
     "start_time": "2021-08-11T16:00:36.069Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Create annual feather files\n",
    "dd_files = {'cps89.ddf': [1989, 1990, 1991],\n",
    "            'cps92.ddf': [1992, 1993]}\n",
    "\n",
    "var_list = ['H-MONTH', 'H-YEAR', 'H-MIS', 'HG-FIPS', 'H-METSTA', 'HG-MSAS',\n",
    "            'H-ID', 'A-LINENO', 'A-AGE', 'A-MARITL', 'A-SEX', 'A-HGA',\n",
    "            'A-RACE', 'A-IND', 'A-OCC', 'A-CLSWKR', 'HG-MSAC', 'HG-CMSA',\n",
    "            'A-USLHRS', 'A-UNMEM', 'A-REORGN', 'A-LFSR', 'A-ENRLW',\n",
    "            'A-UNTYPE', 'A-FNLWGT', 'A-ERNLWT', 'A-HRLYWK', 'H-HHWGT',\n",
    "            'A-HERNTP', 'A-WERNTP', 'A-HRS1', 'A-WKSLK', 'H-HHNUM',\n",
    "            'A-UNCOV', 'A-HGC', 'A-MJIND', 'A-MJOCC', 'A-WKSTAT', \n",
    "            'A-DTOCC', 'A-DTIND', 'A-SPOUSE', 'A-PARENT', 'A-EMPHRS',\n",
    "            'H-HTYPE', 'A-FTPT', 'A-HSCOL', 'A-VET', 'H-FAMINC',\n",
    "            'A-USLFT']\n",
    "\n",
    "# Remove the first two characters from each variable name\n",
    "rename_list = {v: v[2:] for v in var_list if v[0:2] != 'HG'}\n",
    "rename_list['HG-FIPS'] = 'STATEFIPS'\n",
    "rename_list['A-WKSLK'] = 'UNEMPDUR'\n",
    "rename_list['HG-MSAC'] = 'MSA'\n",
    "rename_list['HG-CMSA'] = 'CMSA'\n",
    "rename_list['HG-MSAS'] = 'MSAS'\n",
    "filter_wgt = 'A-FNLWGT'\n",
    "\n",
    "# Map state FIPS codes to two letter codes\n",
    "state_codes = cpsdd['jan94_mar94_dd.txt']['map']['state']\n",
    "region_codes = cpsdd['jan94_mar94_dd.txt']['map']['region']\n",
    "state = lambda x: pd.Categorical(x['STATEFIPS'].map(state_codes))\n",
    "region = lambda x: x['STATE'].map(region_codes)\n",
    "\n",
    "# Metro and Principal city status\n",
    "mpcstat = lambda x: pd.Categorical(\n",
    "    np.where(x.MSAS == 1, 'Principal City',\n",
    "    np.where(x.MSAS == 2, 'Balance',\n",
    "    np.where(x.MSAS == 3, 'Nonmetropolitan',\n",
    "    np.where(x.MSAS == 4, 'Not Identified', None)))))\n",
    "metstat = lambda x: pd.Categorical(\n",
    "    np.where(x.METSTA == 1, 'Metropolitan',\n",
    "    np.where(x.METSTA == 2, 'Nonmetropolitan',\n",
    "    np.where(x.METSTA == 3, 'Not Identified', None))))\n",
    "\n",
    "# 1992-onward educ codes\n",
    "educ_codes = cpsdd['jan94_mar94_dd.txt']['map']['educ']\n",
    "educ = lambda x: x['HGA'].map(educ_codes)\n",
    "educdt = lambda x: pd.Categorical(x['HGA'].map(EducDTMap))\n",
    "\n",
    "# School enrollment\n",
    "schenr = lambda x: pd.Categorical(\n",
    "    np.where(x['ENRLW'] == 1, 1, \n",
    "    np.where(x['ENRLW'] == 2, 0, None)))\n",
    "\n",
    "school = lambda x: pd.Categorical(\n",
    "    np.where(x.HSCOL == 1, 'High School', \n",
    "    np.where((x.HSCOL == 2) & (x.FTPT == 1), 'Full-time College', \n",
    "    np.where((x.HSCOL == 2) & (x.FTPT == 2), 'Part-time College', None))))\n",
    "\n",
    "# major industry group\n",
    "ind_codes = cpsdd['jan94_mar94_dd.txt']['map']['ind']\n",
    "indgrp =  lambda x: pd.Categorical(x['MJIND'].map(ind_codes))\n",
    "\n",
    "# Manager\n",
    "manager = lambda x: np.where(x.DTOCC == 1, 1,\n",
    "                    np.where(x.DTOCC > 0, 0, None))\n",
    "\n",
    "# Unemployment type recode - FIX (MAP IS SLOW)\n",
    "unemptype_map = {1: 'Job Loser', 2: 'Job Loser',\n",
    "                 3: 'Job Leaver',\n",
    "                 4: 'Re-entrant',\n",
    "                 5: 'New Entrant'}\n",
    "\n",
    "unemptype = lambda x: x['UNTYPE'].map(unemptype_map)\n",
    "\n",
    "# Layoff vs looking\n",
    "layoff = lambda x: pd.Categorical(\n",
    "    np.where(x['LFSR'] == 4, 'Layoff',\n",
    "    np.where(x['LFSR'] == 3, 'Looking', None)))\n",
    "\n",
    "# Part-time for economic reasons\n",
    "ptecon = lambda x: pd.Categorical(\n",
    "    np.where(x['WKSTAT'].isin([3, 5]), 1, \n",
    "    np.where(x['WKSTAT'].between(2, 5), 0, None)))\n",
    "\n",
    "# Worked full-time (usually FT or usually PT)\n",
    "workft = lambda x: pd.Categorical(\n",
    "    np.where(x['WKSTAT'] == 2, 1,\n",
    "    np.where(x['WKSTAT'].between(2, 5), 0, None)))\n",
    "\n",
    "# Usually work full-time (35+ hours)\n",
    "uslft = lambda x: pd.Categorical(\n",
    "    np.where((x['USLFT'] == 1) | (x['USLHRS'] >= 35), 1, \n",
    "    np.where(x['USLFT'] == 2, 0, None)))\n",
    "\n",
    "# Not at work during reference week\n",
    "notatwork = lambda x: pd.Categorical(\n",
    "    np.where(x['EMPHRS'].isin([1, 2, 3, 4, 5]), 1,\n",
    "    np.where(x['EMPHRS'].between(6, 16), 0, None)))\n",
    "\n",
    "# Map WBHAO codes for race/ethnicity\n",
    "hisp_map = cpsdd['jan94_mar94_dd.txt']['map']['hisp']\n",
    "hispanic = lambda x: pd.Categorical(np.where(x['REORGN'].isin(hisp_map), 1, 0))\n",
    "race_map = cpsdd['jan94_mar94_dd.txt']['map']['race']\n",
    "wbhao = lambda x: (    # If not hispanic, map race to racial groups\n",
    "    pd.Categorical(np.where(x['REORGN'].isin(hisp_map), 'Hispanic', \n",
    "                            x['RACE'].map(race_map))))\n",
    "wbao = lambda x: pd.Categorical(x['RACE'].map(race_map))\n",
    "\n",
    "# Wage variables\n",
    "wkearn = lambda x: np.where(x.WERNTP >= 0, x.WERNTP, None)\n",
    "hrwage = lambda x: np.where((x.HERNTP < 0) & (x.USLHRS > 0 ) & \n",
    "                            (x.WERNTP > 0), (x.WERNTP / x.USLHRS) / 100, \n",
    "                            np.where(x.HERNTP >= 0, x.HERNTP / 100, None)) \n",
    "priceadj = lambda x: 1 * x.REGION.map(cpi_vals)\n",
    "\n",
    "# Union member and coverage\n",
    "union = lambda x: pd.Categorical(\n",
    "    np.where((x['UNMEM'] == 1) | (x['UNCOV'] == 1), 1, \n",
    "    np.where((x['UNMEM'] == 2) & (x['UNCOV'] == 2), 0, None)),\n",
    "    ordered=True)\n",
    "unionmem = lambda x: pd.Categorical(\n",
    "    np.where(x['UNMEM'] == 1, 1, \n",
    "    np.where(x['UNMEM'] == 2, 0, None)),\n",
    "    ordered=True)\n",
    "\n",
    "# Paid hourly\n",
    "paidhrly = lambda x: pd.Categorical(\n",
    "    np.where(x['HRLYWK'] == 1, 1,\n",
    "    np.where(x['HRLYWK'] == 2, 0, None)))\n",
    "\n",
    "# bd CPS consistent variables\n",
    "age = lambda x: np.where(x['AGE'] > 80, 80, x['AGE'])\n",
    "female = lambda x: np.where(x['SEX'] == 2, 1, 0)\n",
    "faminc = lambda x: pd.Categorical(np.where(x.FAMINC.between(0, 14), \n",
    "                                           x.FAMINC + 1, None))\n",
    "veteran = lambda x: np.where(x['VET'].isin([1, 2, 3, 4, 5]), 1,\n",
    "                             np.where(x['VET'] == 6, 0, None))\n",
    "married = lambda x: np.where(x['MARITL'].isin([1, 2, 3]), 1, \n",
    "                             np.where(x['MARITL'].isin([4,5,6,7]), 0, None))\n",
    "emp = lambda x: np.where(x['LFSR'].isin([1,2]), 1, 0)\n",
    "\n",
    "# Labor force status\n",
    "lfs = lambda x: pd.Categorical(\n",
    "    np.where(x['LFSR'].isin([1, 2]), 'Employed',\n",
    "    np.where(x['LFSR'].isin([3, 4]), 'Unemployed',\n",
    "    np.where(x['LFSR'].isin([5, 6, 7]), 'NILF', np.nan))))\n",
    "\n",
    "# Class of worker\n",
    "cow1 = lambda x: pd.Categorical(\n",
    "    np.where(x['CLSWKR'] == 2, 'Federal Government',\n",
    "    np.where(x['CLSWKR'] == 3, 'State Government',\n",
    "    np.where(x['CLSWKR'] == 4, 'Local Government',\n",
    "    np.where(x['CLSWKR'] == 1, 'Private',\n",
    "    np.where(x['CLSWKR'] == 5, 'Self-employed Incorporated',\n",
    "    np.where(x['CLSWKR'] == 6, 'Self-employed Unincorporated',\n",
    "    np.where(x['CLSWKR'] == 7, 'Without Pay', None))))))))\n",
    "\n",
    "\n",
    "# Weight variables\n",
    "basicwgt = lambda x: np.where(x['FNLWGT'] > 0, x['FNLWGT'] / 100.0, x['FNLWGT'])\n",
    "pworwgt = lambda x: np.where(x['ERNLWT'] > 0, x['ERNLWT'] / 100.0, x['ERNLWT'])\n",
    "hhwgt = lambda x: np.where(x['HHWGT'] > 0, x['HHWGT'] / 100.0, x['HHWGT'])\n",
    "\n",
    "# Read in Consumer Price Index data created by bd_CPS_cpi.ipynb\n",
    "cpi = pd.read_csv('clean/cpi.csv', index_col=[0], parse_dates=True)\n",
    "\n",
    "# Read data dictionaries for information on processing raw data files\n",
    "for ddf, year_list in dd_files.items():\n",
    "    \n",
    "    d = data_dict_reader(ddf, var_list)\n",
    "\n",
    "    dtypes = [(k, v[-1]) for k, v in d.items()]\n",
    "\n",
    "    unpacker = struct_unpacker(d)\n",
    "\n",
    "    # Loop over and process each monthly file in each year\n",
    "    for year in year_list:\n",
    "        file_list = [file for file in os.listdir()\n",
    "                     if file.endswith(f'{str(year)[2:]}pub.dat')]        \n",
    "        combined_data = []\n",
    "        \n",
    "        for file in file_list:\n",
    "            date = pd.to_datetime(f'{year}-{file[:3]}-01')\n",
    "            cpi_vals = cpi.loc[date].to_dict()\n",
    "            df = data_file_reader(file, unpacker, dtypes, filter_wgt)\n",
    "            df = df.rename(rename_list, axis=1)\n",
    "            # Education variable underlying data changes in 1992\n",
    "            if year < 1992:\n",
    "                educ_map = {\n",
    "                    'LTHS': (df['HGA'].between(1, 11)) | ((df['HGA']==12) & \n",
    "                                                          (df['HGC']==2)),\n",
    "                    'HS': (df['HGA']==12) & (df['HGC']==1),\n",
    "                    'SC': (df['HGA'].between(13,15)) | ((df['HGA']==16) & \n",
    "                                                        (df['HGC']==2)),\n",
    "                    'COLL': ((df['HGA']==16) & (df['HGC']==1)) | (df['HGA']==17),\n",
    "                    'ADV': (df['HGA'] >= 18)}\n",
    "                df['EDUC'] = (np.select(educ_map.values(), \n",
    "                                        educ_map.keys(), \n",
    "                                        default=None))\n",
    "                df = df.drop(['HGA', 'HGC'], axis=1)\n",
    "            # Add custom variables defined above\n",
    "            if year >= 1992:\n",
    "                df = df.assign(EDUC = educ, EDUCDT = educdt).drop(['HGA'], axis=1)\n",
    "            df = (df.assign(STATE = state,\n",
    "                            REGION = region,\n",
    "                            METSTAT = metstat,\n",
    "                            MPCSTAT = mpcstat,\n",
    "                            FAMINC = faminc,\n",
    "                            AGE = age,\n",
    "                            FEMALE = female,\n",
    "                            WBHAO = wbhao,\n",
    "                            WBAO = wbao,\n",
    "                            HISPANIC = hispanic,\n",
    "                            VETERAN = veteran,\n",
    "                            SCHENR = schenr,\n",
    "                            SCHOOL = school,\n",
    "                            MARRIED = married,\n",
    "                            EMP = emp,\n",
    "                            LFS = lfs,\n",
    "                            COW1 = cow1,\n",
    "                            UNEMPTYPE = unemptype,\n",
    "                            LAYOFF = layoff,\n",
    "                            PTECON = ptecon,\n",
    "                            WORKFT = workft,\n",
    "                            USLFT = uslft,\n",
    "                            NOTATWORK = notatwork,\n",
    "                            UNION = union,\n",
    "                            UNIONMEM = unionmem,\n",
    "                            PAIDHRLY = paidhrly,\n",
    "                            INDGRP = indgrp,\n",
    "                            MANAGER = manager,\n",
    "                            WKEARN = wkearn,\n",
    "                            HRWAGE = hrwage,\n",
    "                            PRICEADJ = priceadj,\n",
    "                            BASICWGT = basicwgt,\n",
    "                            PWORWGT = pworwgt,\n",
    "                            HHWGT = hhwgt)\n",
    "                    .drop(['STATEFIPS', 'SEX', 'VET', 'MARITL', 'UNTYPE',\n",
    "                           'REORGN', 'ENRLW', 'WKSTAT', 'UNMEM', 'RACE',\n",
    "                           'UNCOV', 'CLSWKR', 'HRLYWK', 'HERNTP', 'EMP',\n",
    "                           'WERNTP', 'LFSR', 'FNLWGT', 'ERNLWT', 'EMPHRS',\n",
    "                           'FTPT', 'HSCOL', 'HHNUM', 'METSTA',\n",
    "                           'MSAS'], axis=1))\n",
    "            df['YEAR'] = year\n",
    "            \n",
    "            # Rename and resize selected variables\n",
    "            df = df.rename({'USLHRS': 'HRSUSL1', 'HRS1': 'HRSACTT',\n",
    "                            'ID': 'HHID',\n",
    "                            'DTIND': 'IND80D', 'DTOCC': 'OCC80D',\n",
    "                            'MJIND': 'IND80M', 'MJOCC': 'OCC80M'}, axis=1)\n",
    "            if year < 1992:\n",
    "                df = df.rename({'IND': 'IND80', 'OCC': 'OCC80'}, axis=1)\n",
    "            if year >= 1992:\n",
    "                df = df.rename({'IND': 'IND90', 'OCC': 'OCC90'}, axis=1)\n",
    "            resize_vars = ['STATE', 'FEMALE', 'VETERAN', 'MARRIED', \n",
    "                           'EDUC', 'UNEMPTYPE', 'REGION', 'YEAR', 'PTECON',\n",
    "                           'CMSA', 'MSA']\n",
    "            df[resize_vars] = df[resize_vars].astype('category')\n",
    "            flt_vars = ['WKEARN', 'HRWAGE', \n",
    "                        'BASICWGT', 'PWORWGT', 'HHWGT']\n",
    "            df[flt_vars] = df[flt_vars].astype('float32')\n",
    "            \n",
    "            # Add QSTNUM and OCCURNUM\n",
    "            df['QSTNUM'] = df.groupby('HHID').ngroup().astype('int32')\n",
    "            df['OCCURNUM'] = ((df.groupby('QSTNUM').cumcount() + 1)\n",
    "                                 .astype('int8'))\n",
    "            \n",
    "            # Major industry recode\n",
    "            for indvar in ['IND80', 'IND90']:\n",
    "                if indvar in df.keys():\n",
    "                    indmap = {i: k for k, v in INDMMap.items() for i in v[indvar]}\n",
    "                    indm = lambda x: pd.Categorical(x[indvar].map(indmap))\n",
    "                    df = df.assign(INDM = indm)            \n",
    "            \n",
    "            # bd CPS household ID\n",
    "            if os.path.isfile(ids_file):\n",
    "                df['CPSID'] = df['QSTNUM'].map(cps_ids_full[date])\n",
    "\n",
    "            combined_data.append(df)\n",
    "            \n",
    "        # Combine monthly files into annual file\n",
    "        df = (pd.concat(combined_data)).reset_index(drop=True)\n",
    "        \n",
    "        ind_occ_cats = ['INDGRP', 'IND80', 'OCC80', 'IND80D', 'OCC80D',\n",
    "                        'IND80M', 'OCC80M', 'IND90', 'OCC90']\n",
    "        cat_vars = [cv for cv in ind_occ_cats if cv in df.keys()]\n",
    "        convert_dict = {cat: 'category' for cat in cat_vars}\n",
    "        df = df.astype(convert_dict)       \n",
    "        \n",
    "        # Store results as feather file\n",
    "        df.to_feather(f'clean/cps{year}.ft')\n",
    "        \n",
    "        # Print outcome\n",
    "        obs = len(df)\n",
    "        cols = len(df.keys())\n",
    "        size = round(df.memory_usage().sum() / 1024**2, 1)\n",
    "        print(f'{year} Done: ({obs:,} records, {cols} variables, {size}MB)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
