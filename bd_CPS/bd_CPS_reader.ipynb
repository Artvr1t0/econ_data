{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS extract\n",
    "\n",
    "bd_CPS_reader.ipynb\n",
    "\n",
    "February 1, 2019\n",
    "\n",
    "Contact: Brian Dew, @bd_econ\n",
    "\n",
    "Requires: `cps_basic_dd.pkl` which is generated by bd_CPS_dd.ipynb\n",
    "\n",
    "-----\n",
    "\n",
    "See [readme](https://github.com/bdecon/econ_data/tree/master/bd_CPS) for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T17:46:57.786163Z",
     "start_time": "2019-02-02T17:46:57.527012Z"
    },
    "code_folding": [
     10
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import struct\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "os.chdir('/home/brian/Documents/CPS/data')\n",
    "\n",
    "def id2_gen(np_mo):\n",
    "    \"\"\"Create HRHHID2 for pre May 2004 data\"\"\"\n",
    "    hrsample = [x[1:3] for x in np_mo['HRSAMPLE']]\n",
    "    hrsersuf = [x.strip() for x in np_mo['HRSERSUF']]\n",
    "    sersuf_d = {a: str(ord(a.lower()) - 96).zfill(2) for a in set(hrsersuf)\n",
    "            if a in list(string.ascii_letters)}\n",
    "    sersuf_d.update({'-1': '00', '-1.0': '00', '0': '00'})\n",
    "    sersuf = list(map(sersuf_d.get, hrsersuf))\n",
    "    np_mo['HUHHNUM'][np_mo['HUHHNUM'] < 0] = 0\n",
    "    huhhnum = np_mo['HUHHNUM'].astype('U1')\n",
    "    \n",
    "    id2 = [''.join(i) for i in zip(hrsample, sersuf, huhhnum)]\n",
    "\n",
    "    return(np.array(id2, dtype='int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T17:46:57.834328Z",
     "start_time": "2019-02-02T17:46:57.787917Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def cps_to_feather(year_list):\n",
    "    \"\"\"Annual partial extracts of monthly CPS files\"\"\"\n",
    "    pr_goods = ['Manufacturing', 'Trade, transportation, and utilities', \n",
    "                'Construction and mining']\n",
    "    pr_servs = ['Finance and business services', 'Education and health', \n",
    "                'Leisure and hospitality', 'Public administration']\n",
    "    female = lambda x: np.where(x['PESEX'] == 2, 1, 0)\n",
    "    state = lambda x: pd.Categorical(x['GESTFIPS'].map(maps['state']))\n",
    "    region = lambda x: x['STATE'].map(maps['region'])\n",
    "    educ = lambda x: pd.Categorical(x['PEEDUCA'].map(maps['educ']))\n",
    "    schenr = lambda x: np.where(x['PESCHENR'] == 1, 1, \n",
    "                                np.where(x['PESCHENR'] == 2, 0, np.nan))\n",
    "    married = lambda x: np.where(x['PRMARSTA'].isin([1, 2, 3]), 1, 0)\n",
    "    wbhao = lambda x: (    # If not hispanic, map race to racial groups\n",
    "        pd.Categorical(np.where(x['PRDTHSP'].isin(maps['hisp']), 'Hispanic', \n",
    "                                x['PRDTRACE'].map(maps['race']))))\n",
    "    wbhaom = lambda x: (    # If not hispanic, map race to racial groups\n",
    "        pd.Categorical(np.where(x['PRDTHSP'].isin(maps['hisp']), 'Hispanic', \n",
    "                                x['PRDTRACE'].map(maps['racem']))))\n",
    "    veteran = lambda x: np.where(x['PEAFEVER'] == 1, 1,\n",
    "                                 np.where(x['PEAFEVER'] == 2, 0, np.nan))\n",
    "    cert = lambda x: np.where(x['PECERT1'] == 1, 1, \n",
    "                              np.where(x['PECERT1']==2, 0, np.nan))\n",
    "    forborn = lambda x: np.where(x['PRCITSHP'].isin([4, 5]), 1, \n",
    "                                 np.where(x['PRCITSHP'].isin([1, 2, 3]), 0, np.nan))\n",
    "    ctybirth94 = lambda x: pd.Categorical(x['PENATVTY'].map(cob[1994]), ordered=False)\n",
    "    ctybirth07 = lambda x: pd.Categorical(x['PENATVTY'].map(cob[2007]), ordered=False)\n",
    "    indgrp =  lambda x: pd.Categorical(x['PRMJIND1'].map(maps['ind']))\n",
    "    lmstat = lambda x: (\n",
    "        pd.Categorical(np.where((x['AGE'] <= 15), 'Under 16', \n",
    "                       np.where(((x['PRWNTJOB']==2) & \n",
    "                                 ((x['PEMLR']==6) | (x['PENLFACT'].isin([1, 2])))), \n",
    "                                'NILF - Disabled/ill',\n",
    "                       np.where(((x['PRWNTJOB']==2) & (x['PENLFACT']==4)), \n",
    "                                'NILF - Family',\n",
    "                       np.where(((x['PRWNTJOB']==2) & \n",
    "                                 ((x['PEMLR']==5) | (x['PENLFACT']==5))), \n",
    "                                'NILF - Retired',\n",
    "                       np.where(((x['PRWNTJOB']==2) & (x['PENLFACT']==3)), \n",
    "                                'NILF - School',\n",
    "                       np.where((x['PEDWWNTO']==1), 'NILF - Discouraged',\n",
    "                       np.where((x['PEMLR'].isin([5, 6, 7])), 'NILF - Other',\n",
    "                       np.where((x['PEMLR'].isin([3, 4])), 'Unemployed',\n",
    "                       np.where(((x['PEMLR'].isin([1, 2])) & \n",
    "                                 ((x['PRFTLF'] == 2) | (x['PEIO1COW'] == 8))),\n",
    "                                'Employed - PT or unpaid',\n",
    "                       np.where((x['PEIO1COW'].isin([1, 2, 3, 5])),\n",
    "                                'Employed - FT - government or nonprofit',\n",
    "                       np.where((x['PEIO1COW'].isin([6, 7])),\n",
    "                                'Employed - FT - self-employed',\n",
    "                       np.where(((x['PEIO1COW'] == 4) & (x['INDGRP'].isin(pr_goods))),\n",
    "                                'Employed - FT - private goods producing',\n",
    "                       np.where(((x['PEIO1COW'] == 4) & (x['INDGRP'].isin(pr_servs))),\n",
    "                                'Employed - FT - private services producing', 'Other'\n",
    "                               )))))))))))))))\n",
    "    emp = lambda x: np.where(x['PREMPNOT']==1, 1, 0)\n",
    "    mjh = lambda x: np.where(x['PRSJMJ']==2, 1, np.where(x['PRSJMJ']==1, 0, np.nan))\n",
    "    unempdur = lambda x: x['PRUNEDUR']\n",
    "    unemptype = lambda x: (\n",
    "        pd.Categorical(np.where(x['PRUNTYPE'].isin([1, 2, 3]), 'Job Loser',\n",
    "                       np.where(x['PRUNTYPE'] == 4, 'Job Leaver',\n",
    "                       np.where(x['PRUNTYPE'] == 5, 'Re-entrant',\n",
    "                       np.where(x['PRUNTYPE'] == 6, 'New Entrant', np.nan))))))\n",
    "    ptecon = lambda x: np.where(x['PRWKSTAT'].isin([3, 6]), 1, \n",
    "                               np.where(x['PRWKSTAT'].between(2, 10), 0, np.nan))\n",
    "    wkwage = lambda x: np.where(x['PRERNWA'] > 0, x['PRERNWA'] / 100.0, np.nan)\n",
    "    hrwage = lambda x: np.where((x['PRERNHLY'] < 0) & (x['PEHRUSL1'] > 0 ) & \n",
    "                                (x['PRERNWA'] > 0), x['PRERNWA'] / x['PEHRUSL1'], \n",
    "                                np.where(x['PRERNHLY'] > 0, x['PRERNHLY'], \n",
    "                                         np.nan)) / 100  \n",
    "    ottcamt = lambda x: np.where(x['PUERN2'] > 0, x['PUERN2'] / 100.0, np.nan)\n",
    "    rhrwage = lambda x: (np.where(x['HRWAGE'] > 0, \n",
    "                 x['HRWAGE'] * x['REGION'].map(cpi_vals), np.nan))\n",
    "    rhrwage2 = lambda x: (\n",
    "        np.where(x['HRWAGE'] > 0, x['HRWAGE'] * cpi_vals['ALL'], np.nan))\n",
    "    rwkwage = lambda x: (np.where(x['WKWAGE'] > 0, \n",
    "                 x['WKWAGE'] * x['REGION'].map(cpi_vals), np.nan))\n",
    "    rottcamt = lambda x: (np.where(x['OTTCAMT'] > 0, \n",
    "                 x['OTTCAMT'] * x['REGION'].map(cpi_vals), np.nan))\n",
    "    drop_vars = ['PESEX', 'PRUNTYPE', 'PRERNWA', 'PRWKSTAT', 'PEDWWNTO',\n",
    "                 'PRCITSHP', 'PENLFRET', 'PESCHENR', 'GESTFIPS', 'PRWNTJOB',\n",
    "                 'PRUNEDUR', 'PEAFEVER', 'PRSJMJ', 'PUERN2']\n",
    "    cpsdd = pickle.load(open('cps_basic_dd.pkl', 'rb'))\n",
    "    cob = pickle.load(open('country_of_birth.pkl', 'rb')) # From CEPR program\n",
    "    cpi = pd.read_csv('clean/cpi.csv', index_col=[0], parse_dates=True)\n",
    "    data_path = '/home/brian/Documents/CPS/data/'\n",
    "    data_dir = os.listdir(data_path)\n",
    "    dd_file = None\n",
    "    for year in year_list:\n",
    "        file_ending = f'{str(year)[2:]}pub.dat'\n",
    "        mo_dat_files = [file for file in data_dir\n",
    "                        if file.endswith(file_ending)]   \n",
    "        combined_data = [] \n",
    "        for file in mo_dat_files:\n",
    "            date = pd.to_datetime(f'{year}-{file[:3]}-01')\n",
    "            cpi_vals = cpi.loc[date].to_dict()\n",
    "            if dd_file != cpsdd['matcher'][file]:\n",
    "                dd_file = cpsdd['matcher'][file]\n",
    "                dd = cpsdd[dd_file]['dd']\n",
    "                dtypes = [(k, v[-1]) for k, v in dd.items()]\n",
    "                maps = cpsdd[dd_file]['map']\n",
    "                ws, we = dd['PWSSWGT'][:2]\n",
    "                unpack_fmt = cpsdd[dd_file]['unpack_fmt']\n",
    "                unpacker = struct.Struct(unpack_fmt).unpack_from\n",
    "            raw_mo_data = open(f'{data_path}{file}', 'rb')\n",
    "            if file == 'mar04pub.dat':\n",
    "                mo_data = [unpacker(row) for row in raw_mo_data \n",
    "                           if b'**' not in row]\n",
    "            else:\n",
    "                mo_data = [unpacker(row) for row in raw_mo_data]  \n",
    "            np_mo = np.array(mo_data, dtype=dtypes)\n",
    "            np_mo = np_mo[(np_mo['PRTAGE'] > -1) & \n",
    "                          (np_mo['PWSSWGT'] > 0)]\n",
    "            for wgt in maps['wgt']:\n",
    "                np_mo[wgt] = np.divide(np_mo[wgt], 10000)\n",
    "            dfm = (pd.DataFrame(np_mo)\n",
    "                     .rename({'PRTAGE':'AGE'}, axis=1)\n",
    "                     .assign(FEMALE = female,\n",
    "                             STATE = state,\n",
    "                             REGION = region,\n",
    "                             EDUC = educ,\n",
    "                             SCHENR = schenr,\n",
    "                             MARRIED = married,\n",
    "                             WBHAO = wbhao,\n",
    "                             FORBORN = forborn,\n",
    "                             VETERAN = veteran,\n",
    "                             INDGRP = indgrp,\n",
    "                             LMSTAT = lmstat,\n",
    "                             EMP = emp,\n",
    "                             MJH = mjh,\n",
    "                             UNEMPTYPE = unemptype,\n",
    "                             UNEMPDUR = unempdur,\n",
    "                             PTECON = ptecon,\n",
    "                             WKWAGE = wkwage,\n",
    "                             HRWAGE = hrwage,\n",
    "                             OTTCAMT = ottcamt,\n",
    "                             RHRWAGE = rhrwage,\n",
    "                             RHRWAGE2 = rhrwage2,\n",
    "                             RWKWAGE = rwkwage,\n",
    "                             ROTTCAMT = rottcamt)\n",
    "                     .drop(drop_vars, axis=1))\n",
    "            # December 2007 revised weights\n",
    "            if date == pd.to_datetime('2007-12-01'):\n",
    "                df_rev = pd.read_feather(f'{data_path}clean/cps_dec07_rev.ft')\n",
    "                dfm = pd.merge(dfm, df_rev)\n",
    "                dfm['PWSSWGT'] = dfm['NWSSWGT']\n",
    "                dfm['PWCMPWGT'] = dfm['NWCMPWGT']\n",
    "                dfm = dfm.drop(['NWSSWGT', 'NWCMPWGT'], axis=1)\n",
    "            if date >= pd.to_datetime('1999-11-01'):\n",
    "                resize_vars = ['PRNMCHLD', 'PRCHLD']\n",
    "                dfm[resize_vars] = dfm[resize_vars].astype('int8')\n",
    "            if year < 1997:\n",
    "                dfm = dfm.assign(CTYBIRTH = ctybirth94)\n",
    "            if year >= 1997:\n",
    "                dfm = dfm.assign(CTYBIRTH = ctybirth07)\n",
    "            dfm = dfm.drop(['PENATVTY'], axis=1)\n",
    "            if year < 1998:\n",
    "                dfm['HRYEAR4'] = dfm['HRYEAR'] + 1900\n",
    "                dfm = dfm.drop(['HRYEAR'], axis=1)\n",
    "                dfm['BASICWGT'] = dfm['PWSSWGT']\n",
    "            if year > 1997:\n",
    "                dfm['BASICWGT'] = dfm['PWCMPWGT']\n",
    "            if year > 2002:\n",
    "                dfm = dfm.assign(WBHAOM = wbhaom)\n",
    "            if year > 2016:\n",
    "                dfm = dfm.assign(CERT = cert).drop(['PECERT1'], axis=1)\n",
    "                dfm['CERT'] = dfm['CERT'].astype('category')\n",
    "            if maps['id2'] == True:\n",
    "                dfm['HRHHID2'] = id2_gen(np_mo)\n",
    "                dfm = dfm.drop(['HRSAMPLE', 'HRSERSUF', 'HUHHNUM'], axis=1)\n",
    "            dfm = dfm.rename({'HRYEAR4':'YEAR', 'HRMONTH': 'MONTH'}, axis=1)\n",
    "            resize_vars = ['SCHENR', 'FORBORN', 'VETERAN', 'MJH', 'MARRIED',\n",
    "                           'EMP', 'FEMALE', 'PTECON', 'REGION', 'UNEMPTYPE']\n",
    "            dfm[resize_vars] = dfm[resize_vars].astype('category')\n",
    "            wage_vars = ['WKWAGE', 'HRWAGE', 'OTTCAMT', 'RHRWAGE', 'RHRWAGE2', \n",
    "                         'RWKWAGE', 'ROTTCAMT']\n",
    "            dfm[wage_vars] = dfm[wage_vars].astype('float32')\n",
    "            combined_data.append(dfm)\n",
    "        df = (pd.concat(combined_data, sort=False)\n",
    "              .reset_index(drop=True)\n",
    "              .assign(YEAR = lambda x: pd.Categorical(x['YEAR'])))\n",
    "        df['CTYBIRTH'] = df['CTYBIRTH'].astype('category')\n",
    "        df = df.rename({'PRTAGE': 'AGE', 'HRYEAR4':'YEAR', \n",
    "                        'HRMONTH': 'MONTH', 'PEHRUSLT': 'HRSUSLT',\n",
    "                        'PEHRUSL1': 'HRSUSL1', 'PEHRUSL2': 'HRSUSL2',\n",
    "                        'PEHRACT1': 'HRSACT1', 'PEHRACT2': 'HRSACT2',\n",
    "                        'PEHRACTT': 'HRSACTT'}, axis=1)\n",
    "        # Merge in the 2000-revised weights here\n",
    "        if 2000 <= year <= 2002:\n",
    "            rev_wgts = (pd.read_feather(f'{data_path}clean/cps_wgt_rev.ft')\n",
    "                          .query('YEAR == @year'))\n",
    "            df = pd.merge(df, rev_wgts)\n",
    "            df['BASICWGT'] = df['NWCMPWGT']\n",
    "            df['PWORWGT'] = df['NWORWGT']\n",
    "            df['PWSSWGT'] = df['NWSSWGT']\n",
    "            df = (df.drop(['NWCMPWGT', 'NWORWGT', 'NWSSWGT'], axis=1)\n",
    "                    .assign(YEAR = lambda x: pd.Categorical(x['YEAR'])))\n",
    "        # Merge in revised union data\n",
    "        if year in [2001, 2002]:\n",
    "            rev_df = (pd.read_feather(f'{data_path}clean/cps_union_rev.ft')\n",
    "                        .query('YEAR == @year'))\n",
    "            df = pd.merge(df, rev_df)\n",
    "            df['PEERNLAB'] = df['NEERNLAB']\n",
    "            df['PEERNCOV'] = df['NEERNCOV']\n",
    "            df = (df.drop(['NEERNLAB', 'NEERNCOV'], axis=1)\n",
    "                    .assign(YEAR = lambda x: pd.Categorical(x['YEAR'])))\n",
    "        if year >= 1998:    \n",
    "            df = df.drop(['QSTNUM', 'OCCURNUM'], axis=1)\n",
    "        df.to_feather(f'clean/cps{year}.ft')\n",
    "        print(f'{year} Done: ({len(df):,} records, {len(df.keys())} variables)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-02T17:56:57.401372Z",
     "start_time": "2019-02-02T17:46:57.835619Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994 Done: (1,672,934 records, 64 variables)\n",
      "1995 Done: (1,648,060 records, 64 variables)\n",
      "1996 Done: (1,461,469 records, 64 variables)\n",
      "1997 Done: (1,462,817 records, 64 variables)\n",
      "1998 Done: (1,461,394 records, 65 variables)\n",
      "1999 Done: (1,465,602 records, 67 variables)\n",
      "2000 Done: (1,460,724 records, 67 variables)\n",
      "2001 Done: (1,560,960 records, 67 variables)\n",
      "2002 Done: (1,703,017 records, 67 variables)\n",
      "2003 Done: (1,685,264 records, 68 variables)\n",
      "2004 Done: (1,656,144 records, 70 variables)\n",
      "2005 Done: (1,644,787 records, 70 variables)\n",
      "2006 Done: (1,628,798 records, 70 variables)\n",
      "2007 Done: (1,611,901 records, 70 variables)\n",
      "2008 Done: (1,600,790 records, 70 variables)\n",
      "2009 Done: (1,617,099 records, 71 variables)\n",
      "2010 Done: (1,621,021 records, 71 variables)\n",
      "2011 Done: (1,600,068 records, 71 variables)\n",
      "2012 Done: (1,588,264 records, 71 variables)\n",
      "2013 Done: (1,576,085 records, 71 variables)\n",
      "2014 Done: (1,582,739 records, 71 variables)\n",
      "2015 Done: (1,561,469 records, 71 variables)\n",
      "2016 Done: (1,553,528 records, 71 variables)\n",
      "2017 Done: (1,524,812 records, 72 variables)\n",
      "2018 Done: (1,474,979 records, 72 variables)\n"
     ]
    }
   ],
   "source": [
    "cps_to_feather(range(1994, 2019))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
