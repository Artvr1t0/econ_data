{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bd econ CPS extract\n",
    "\n",
    "bd_CPS_reader.ipynb\n",
    "\n",
    "September 20, 2018\n",
    "\n",
    "@bd_econ\n",
    "\n",
    "Requires: `cps_basic_dd.pkl` which is generated by bd_CPS_dd.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T22:36:19.047740Z",
     "start_time": "2018-10-10T22:36:18.741376Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import struct\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "os.chdir('/home/brian/Documents/CPS/data')\n",
    "\n",
    "\n",
    "def id2_gen(np_mo):\n",
    "    \"\"\"Create HRHHID2 for pre May 2004 data\"\"\"\n",
    "    hrsample = [x[1:3] for x in np_mo['HRSAMPLE']]\n",
    "    hrsersuf = [x.strip() for x in np_mo['HRSERSUF']]\n",
    "    sersuf_d = {a: str(ord(a.lower()) - 96).zfill(2) for a in set(hrsersuf)\n",
    "            if a in list(string.ascii_letters)}\n",
    "    sersuf_d.update({'-1': '00', '-1.0': '00', '0': '00'})\n",
    "    sersuf = list(map(sersuf_d.get, hrsersuf))\n",
    "    np_mo['HUHHNUM'][np_mo['HUHHNUM'] < 0] = 0\n",
    "    huhhnum = np_mo['HUHHNUM'].astype('U1')\n",
    "    \n",
    "    id2 = [''.join(i) for i in zip(hrsample, sersuf, huhhnum)]\n",
    "\n",
    "    return(np.array(id2, dtype='int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T01:09:04.323529Z",
     "start_time": "2018-10-11T01:09:04.304530Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def cps_to_feather(year_list):\n",
    "    \"\"\"Annual partial extracts of monthly CPS files\"\"\"\n",
    "    female = lambda x: np.where(x['PESEX'] == 2, 1, 0)\n",
    "    state = lambda x: pd.Categorical(x['GESTFIPS'].map(maps['state']))\n",
    "    educ = lambda x: pd.Categorical(x['PEEDUCA'].map(maps['educ']))\n",
    "    married = lambda x: np.where(x['PRMARSTA'].isin([1,2,3]), 1, 0)\n",
    "    wbhao = lambda x: pd.Categorical(np.where(x['PRDTHSP'].isin(maps['hisp']), \n",
    "                                              'Hispanic', \n",
    "                                              x['PRDTRACE'].map(maps['race'])))\n",
    "    emp = lambda x: np.where(x['PREMPNOT']==1, 1, 0)\n",
    "    hrwage = lambda x: np.where((x['PRERNHLY'] < 0) & (x['PEHRUSL1'] > 0 ) & \n",
    "                                (x['PRERNWA'] > 0), x['PRERNWA'] / x['PEHRUSL1'], \n",
    "                                np.where(x['PRERNHLY'] > 0, x['PRERNHLY'], \n",
    "                                         np.nan)) / 100\n",
    "    cpsdd = pickle.load(open('cps_basic_dd.pkl', 'rb'))\n",
    "    data_path = '/home/brian/Documents/CPS/data/'\n",
    "    data_dir = os.listdir(data_path)\n",
    "    dd_file = None\n",
    "    for year in year_list:\n",
    "        file_ending = f'{str(year)[2:]}pub.dat'\n",
    "        mo_dat_files = [file for file in data_dir\n",
    "                        if file.endswith(file_ending)]   \n",
    "        combined_data = [] \n",
    "        for file in mo_dat_files:\n",
    "            if dd_file != cpsdd['matcher'][file]:\n",
    "                dd_file = cpsdd['matcher'][file]\n",
    "                dd = cpsdd[dd_file]['dd']\n",
    "                dtypes = [(k, v[-1]) for k, v in dd.items()]\n",
    "                maps = cpsdd[dd_file]['map']\n",
    "                ws, we = dd['PWSSWGT'][:2]\n",
    "                unpack_fmt = cpsdd[dd_file]['unpack_fmt']\n",
    "                unpacker = struct.Struct(unpack_fmt).unpack_from\n",
    "            raw_mo_data = open(f'{data_path}{file}', 'rb')\n",
    "            mo_data = [unpacker(row) for row in raw_mo_data]  \n",
    "            np_mo = np.array(mo_data, dtype=dtypes)\n",
    "            np_mo = np_mo[(np_mo['PRTAGE'] > 15) & \n",
    "                          (np_mo['PWSSWGT'] > 0)]\n",
    "            for wgt in maps['wgt']:\n",
    "                np_mo[wgt] = np.divide(np_mo[wgt], 10000)\n",
    "            dfm = (pd.DataFrame(np_mo)\n",
    "                     .rename({'PRTAGE':'AGE'}, axis=1)\n",
    "                     .assign(FEMALE = female,\n",
    "                             STATE = state,\n",
    "                             EDUC = educ,\n",
    "                             MARRIED = married,\n",
    "                             WBHAO = wbhao,\n",
    "                             EMP = emp,\n",
    "                             HRWAGE = hrwage)\n",
    "                     .drop(['PESEX', 'GESTFIPS'], axis=1))\n",
    "            if year < 1998:\n",
    "                dfm['HRYEAR4'] = dfm['HRYEAR'] + 1900\n",
    "                dfm = dfm.drop(['HRYEAR'], axis=1)\n",
    "            if maps['id2'] == True:\n",
    "                dfm['HRHHID2'] = id2_gen(np_mo)\n",
    "                dfm = dfm.drop(['HRSAMPLE', 'HRSERSUF', 'HUHHNUM'], axis=1)\n",
    "            combined_data.append(dfm)\n",
    "        df = (pd.concat(combined_data, sort=False)\n",
    "              .reset_index(drop=True)\n",
    "              .assign(HRYEAR4 = lambda x: pd.Categorical(x['HRYEAR4'])))\n",
    "        df.to_feather(f'clean/cps{year}.ft')\n",
    "        print(f'{year} Done: ({len(df):,} records, {len(df.keys())} variables)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T01:15:43.950045Z",
     "start_time": "2018-10-11T01:09:05.712239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994 Done: (1,264,881 records, 52 variables)\n",
      "1995 Done: (1,245,737 records, 52 variables)\n",
      "1996 Done: (1,103,811 records, 52 variables)\n",
      "1997 Done: (1,109,347 records, 52 variables)\n",
      "1998 Done: (1,112,012 records, 53 variables)\n",
      "1999 Done: (1,119,277 records, 53 variables)\n",
      "2000 Done: (1,116,447 records, 53 variables)\n",
      "2001 Done: (1,197,384 records, 53 variables)\n",
      "2002 Done: (1,306,879 records, 53 variables)\n",
      "2003 Done: (1,297,060 records, 54 variables)\n",
      "2004 Done: (1,277,835 records, 55 variables)\n",
      "2005 Done: (1,273,399 records, 55 variables)\n",
      "2006 Done: (1,266,304 records, 55 variables)\n",
      "2007 Done: (1,255,147 records, 55 variables)\n",
      "2008 Done: (1,252,180 records, 55 variables)\n",
      "2009 Done: (1,268,277 records, 56 variables)\n",
      "2010 Done: (1,271,629 records, 56 variables)\n",
      "2011 Done: (1,260,276 records, 56 variables)\n",
      "2012 Done: (1,253,486 records, 56 variables)\n",
      "2013 Done: (1,248,291 records, 56 variables)\n",
      "2014 Done: (1,256,358 records, 56 variables)\n",
      "2015 Done: (1,240,426 records, 56 variables)\n",
      "2016 Done: (1,238,834 records, 56 variables)\n",
      "2017 Done: (1,221,732 records, 56 variables)\n",
      "2018 Done: (790,613 records, 56 variables)\n"
     ]
    }
   ],
   "source": [
    "cps_to_feather(range(1994, 2019))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
