{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique CPS Household ID \n",
    "\n",
    "February 12, 2019\n",
    "\n",
    "Brian Dew, @bd_econ\n",
    "\n",
    "-----\n",
    "\n",
    "Drawn primarily from the description of the IPUMS CPSID. Works currently for 1998-onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:01:00.686836Z",
     "start_time": "2019-02-12T15:00:59.022515Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 0.24.1\n",
      "numpy: 1.15.4\n",
      "ID dictionary file exists\n"
     ]
    }
   ],
   "source": [
    "# Import preliminaries\n",
    "import os, re, struct, pickle, string\n",
    "import pandas as pd\n",
    "print('pandas:', pd.__version__)\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "print('numpy:', np.__version__)\n",
    "from bd_CPS_details import StatesMap, DataDict\n",
    "\n",
    "os.chdir('/home/brian/Documents/CPS/data')\n",
    "\n",
    "dd_matcher = pickle.load(open('cps_basic_dd.pkl', 'rb'))['matcher']\n",
    "\n",
    "\n",
    "# Storage of IDs in pickled dictionary\n",
    "ids_file = 'CPS_unique_ids.pkl'\n",
    "if os.path.isfile(ids_file):\n",
    "    print('ID dictionary file exists')\n",
    "    cps_ids_full = pickle.load(open(ids_file, 'rb'))\n",
    "else:\n",
    "    cps_ids_full = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:01:00.696172Z",
     "start_time": "2019-02-12T15:01:00.688404Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Return regex pattern that will parse data dictionary dd_file\n",
    "def return_dd_parser(dd_file):\n",
    "    \n",
    "    DataDict = {'January_2017_Record_Layout.txt': \n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'January_2015_Record_Layout.txt':\n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'January_2014_Record_Layout.txt':\n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'January_2013_Record_Layout.txt':\n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'may12dd.txt':\n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan10dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan09dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan07dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'augnov05dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'may04dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan03dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan98dd.asc':\n",
    "                'D (\\w+)\\s+(\\d{1,2})\\s+(\\d+)\\s+',\n",
    "                'jan98dd2.asc':\n",
    "                'D (\\w+)\\s+(\\d{1,2})\\s+(\\d+)\\s+',\n",
    "                'sep95_dec97_dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jun95_aug95_dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'apr94_may95_dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan94_mar94_dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'}\n",
    "    \n",
    "    return DataDict[dd_file]\n",
    "\n",
    "\n",
    "# Create HHID2 for pre May 2004 data\n",
    "def id2_gen(np_mo):\n",
    "    hrsample = [x[1:3] for x in np_mo['HRSAMPLE']]\n",
    "    hrsersuf = [x.strip() for x in np_mo['HRSERSUF']]\n",
    "    sersuf_d = {a: str(ord(a.lower()) - 96).zfill(2) for a in set(hrsersuf)\n",
    "            if a in list(string.ascii_letters)}\n",
    "    sersuf_d.update({'-1': '00', '-1.0': '00', '0': '00'})\n",
    "    sersuf = list(map(sersuf_d.get, hrsersuf))\n",
    "    np_mo.loc[np_mo['HUHHNUM'] < 0, 'HUHHNUM'] = 0\n",
    "    huhhnum = np_mo['HUHHNUM'].astype('U1')\n",
    "    \n",
    "    id2 = [''.join(i) for i in zip(hrsample, sersuf, huhhnum)]\n",
    "\n",
    "    return(np.array(id2, dtype='uint32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:01:00.742868Z",
     "start_time": "2019-02-12T15:01:00.697503Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "raw_monthly_data_file_list = [file for file in os.listdir() \n",
    "                              if file.endswith('pub.dat') \n",
    "                              and (pd.to_datetime(file[:5], format='%b%y')\n",
    "                                   not in cps_ids_full.keys())]\n",
    "\n",
    "#raw_monthly_data_file_list = ['nov04pub.dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T15:01:01.402588Z",
     "start_time": "2019-02-12T15:01:00.744624Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total months of IDs: 285\n"
     ]
    }
   ],
   "source": [
    "# Loop over files of interest and generate unique IDs\n",
    "for file in raw_monthly_data_file_list:\n",
    "    # Details for matching new file to previous data\n",
    "    curr_mo = pd.to_datetime(file[:5], format='%b%y')\n",
    "    \n",
    "    # Handling dates before and at break\n",
    "    if curr_mo < pd.to_datetime('1995-05-01'):\n",
    "        continue\n",
    "\n",
    "    print('Current month:', curr_mo)\n",
    "    \n",
    "    # Identify possible matching months\n",
    "    mo_diffs = [1, 2, 3, 9, 10, 11, 12, 13, 14, 15]\n",
    "    poss_mos = [poss_mo for poss_mo in [curr_mo - pd.DateOffset(months=mo_diff)\n",
    "                for mo_diff in mo_diffs] \n",
    "                if poss_mo >= pd.to_datetime('1995-05-01')]\n",
    "    \n",
    "    # Put in format to match with bd CPS data\n",
    "    yymms = [int(pm.strftime('%y%m')) for pm in poss_mos]\n",
    "\n",
    "    # Which annual bd CPS files to pull\n",
    "    years = list(set([pm.year for pm in poss_mos]))\n",
    "    if curr_mo == pd.to_datetime('1995-05-01'):\n",
    "        yymms = ['9505']\n",
    "        years = [1995]\n",
    "    bd_CPS_files = [f'cps{year}.ft' for year in years]\n",
    "    \n",
    "    # For each month in sample, which months can match?\n",
    "    match_months = {\n",
    "        2: [1],\n",
    "        3: [2, 1],\n",
    "        4: [3, 2, 1],\n",
    "        5: [12, 11, 10, 9],\n",
    "        6: [13, 12, 11, 10, 1],\n",
    "        7: [14, 13, 12, 11, 2, 1],\n",
    "        8: [15, 14, 13, 12, 3, 2, 1]\n",
    "    }\n",
    "    \n",
    "    # Return list of yymms to search for each MIS based on curr_mo\n",
    "    search_list = {mis: [int(search_mo.strftime('%y%m')) for search_mo in \n",
    "                         [curr_mo - pd.DateOffset(months=mo_diff) \n",
    "                          for mo_diff in match_months[mis]] \n",
    "                         if search_mo > pd.to_datetime('1995-08-01')]\n",
    "                   for mis in [2, 3, 4, 5, 6, 7, 8]}\n",
    "\n",
    "    # Background to read current monthly file\n",
    "    # read data dictionary text file \n",
    "    dd_file = dd_matcher[file]\n",
    "    data_dict = open(dd_file, 'r', encoding='iso-8859-1').read()\n",
    "    if dd_file == 'may04dd.txt':\n",
    "        data_dict = data_dict.replace('HRHHID (partII)', 'HRHHID2')\n",
    "\n",
    "    # manually list out the IDs for series of interest \n",
    "    var_names = ['HRMONTH', 'HRYEAR4', 'HRMIS', 'QSTNUM', 'OCCURNUM', \n",
    "                 'HRHHID', 'HRHHID2', 'GESTFIPS', 'HWHHWGT']   \n",
    "\n",
    "    if curr_mo < pd.to_datetime('2004-05-01'):\n",
    "        var_names = ['HRMONTH', 'HRYEAR4', 'HRMIS', 'QSTNUM', 'OCCURNUM', \n",
    "                     'HRHHID', 'HRSAMPLE', 'HRSERSUF', 'HUHHNUM', 'GESTFIPS', \n",
    "                     'HWHHWGT', 'HRYEAR']      \n",
    "\n",
    "    # regular expression matching series name and data dict pattern\n",
    "    p = return_dd_parser(dd_file)\n",
    "\n",
    "    # pick data type based on size of variable\n",
    "    def id_dtype(size, name):\n",
    "        size = int(size)\n",
    "        dtype = ('U4' if name in ['HRSAMPLE']\n",
    "                 else 'U2' if name in ['HRSERSUF']\n",
    "                 else 'intp' if size > 9 \n",
    "                 else 'int32' if size > 4 \n",
    "                 else 'int16' if size > 2 \n",
    "                 else 'int8')\n",
    "        return dtype\n",
    "\n",
    "    # dictionary of variable name: [start, end, and length + 's']\n",
    "    if dd_file in ['jan98dd.asc', 'jan98dd2.asc']:\n",
    "        d = {s[0]: [int(s[2])-1, int(s[2])+int(s[1])-1, \n",
    "                    f'{s[1]}s', id_dtype(s[1], s[0])] \n",
    "             for s in re.findall(p, data_dict) if s[0] in var_names}       \n",
    "    else:\n",
    "        d = {s[0]: [int(s[2])-1, int(s[3]), f'{s[1]}s', id_dtype(s[1], s[0])]\n",
    "         for s in re.findall(p, data_dict) if s[0] in var_names}\n",
    "\n",
    "    # data types\n",
    "    dtypes = [(k, v[-1]) for k, v in d.items()]\n",
    "\n",
    "    # weight variable start and end location\n",
    "    ws, we = d['HWHHWGT'][:2]\n",
    "\n",
    "    # lists of variable starts, ends, and lengths\n",
    "    start, end, width, dtype = zip(*d.values())\n",
    "\n",
    "    # create list of which characters to skip in each row\n",
    "    skip = ([f'{s - e}x' for s, e in zip(start, [0] + list(end[:-1]))])\n",
    "\n",
    "    # create format string by joining skip and variable segments\n",
    "    unpack_fmt = ''.join([j for i in zip(skip, width) for j in i])\n",
    "\n",
    "    # struct can interpret row bytes with the format string\n",
    "    unpacker = struct.Struct(unpack_fmt).unpack_from\n",
    "\n",
    "    # Assign new date variable\n",
    "    date = lambda x: (((x.HRYEAR4.astype(np.int32) * 100) + \n",
    "                      x.HRMONTH.astype(np.int8)) % 10000)\n",
    "    \n",
    "    # 1998 and onward have OCCURNUM to keep first in HH\n",
    "    if curr_mo >= pd.to_datetime('1998-01-01'):\n",
    "        # first occurance to set household start and end\n",
    "        hs, he = d['OCCURNUM'][:2]\n",
    "    \n",
    "        # Read new monthly file\n",
    "        data = [unpacker(row) for row in open(file, 'rb') \n",
    "                if (row[ws:we].strip() > b'0')\n",
    "                and (row[hs:he].strip() == b'1')]\n",
    "\n",
    "        # Convert to dataframe using specified weights\n",
    "        df = (pd.DataFrame(np.array(data, dtype=dtypes))\n",
    "                .assign(DATE = date))\n",
    "        \n",
    "        # Create HHID2 if necessary\n",
    "        if curr_mo < pd.to_datetime('2004-05-01'):\n",
    "            df['HRHHID2'] = id2_gen(df)\n",
    "        \n",
    "    else:\n",
    "        # Read new monthly file\n",
    "        data = [unpacker(row) for row in open(file, 'rb') \n",
    "                if (row[ws:we].strip() > b'0')]\n",
    "\n",
    "        # Convert to dataframe using specified weights\n",
    "        df = pd.DataFrame(np.array(data, dtype=dtypes))\n",
    "        \n",
    "        # Create HHID2 if necessary\n",
    "        if curr_mo < pd.to_datetime('2004-05-01'):\n",
    "            df['HRHHID2'] = id2_gen(df)        \n",
    "\n",
    "        # Keep only first observation in each HH\n",
    "        df = df.drop_duplicates(subset=['HRHHID', 'HRHHID2'], keep='first')\n",
    "        \n",
    "        # Create HRYEAR4 from HRYEAR\n",
    "        df['HRYEAR4'] = df['HRYEAR'] + 1900\n",
    "        df = df.drop(['HRYEAR'], axis=1)\n",
    "        \n",
    "        # Assign date\n",
    "        df = df.assign(DATE = date)\n",
    "        \n",
    "        # Create QSTNUM\n",
    "        df['QSTNUM'] = df.groupby(['HRHHID','HRHHID2']).ngroup().astype('int32')\n",
    "\n",
    "    # Rename HHIDs\n",
    "    df = df.rename({'HRHHID': 'HHID', 'HRHHID2': 'HHID2'}, axis=1)\n",
    "\n",
    "    # Need to map state to state id codes\n",
    "    df['STATE'] = df['GESTFIPS'].map(StatesMap)\n",
    "\n",
    "    # Drop GESTFIPS and OCCURNUM\n",
    "    df = df.drop(['GESTFIPS'], axis=1)\n",
    "    if curr_mo >= pd.to_datetime('1998-01-01'):\n",
    "        df = df.drop(['OCCURNUM'], axis=1)\n",
    "        \n",
    "    tot_hh = len(df)\n",
    "    print('Total HHs in sample:', tot_hh)\n",
    "\n",
    "    # Read potential match data\n",
    "    keep_cols = ['YEAR', 'MONTH', 'MIS', 'HHID', 'HHID2', 'QSTNUM', \n",
    "                 'OCCURNUM', 'STATE']\n",
    "\n",
    "    date = lambda x: (((x.YEAR.astype(np.int32) * 100) + \n",
    "                      x.MONTH.astype(np.int8)) % 10000)\n",
    "    \n",
    "    mdf = (pd.concat(\n",
    "        [(pd.read_feather(f'clean/cps{year}.ft', columns=keep_cols)\n",
    "            .query('OCCURNUM == 1')\n",
    "            .assign(DATE = date))\n",
    "         for year in years], sort=False))\n",
    "\n",
    "    mdf = (mdf[mdf['DATE'].isin(yymms)].drop(['MONTH', 'YEAR'], axis=1))\n",
    "\n",
    "    # Merge data\n",
    "    d = {}\n",
    "\n",
    "    # MIS = 1 households get current id\n",
    "    dfmis1 = df.loc[df['HRMIS'] == 1, ['QSTNUM', 'DATE']]\n",
    "    dfmis1['ID'] = dfmis1['DATE'] * 100000 + dfmis1['QSTNUM']\n",
    "    mis1id = dfmis1.set_index('QSTNUM')['ID'].to_dict()\n",
    "    d.update(mis1id)\n",
    "    print('New HHs (MIS1):', len(d))\n",
    "\n",
    "    df = df.loc[df['HRMIS'] > 1]\n",
    "    dft = df\n",
    "\n",
    "    # Loop over MIS and potentional matches to find matched id\n",
    "    for mis in [2, 3, 4, 5, 6, 7, 8]:    \n",
    "        for pm in search_list[mis]:\n",
    "            results = (dft.loc[dft['HRMIS'] == mis]\n",
    "                          .merge(mdf[mdf['DATE'] == pm], \n",
    "                                 on=['HHID', 'HHID2', 'STATE']))\n",
    "\n",
    "            results['ID'] = results['DATE_y'] * 100000 + results['QSTNUM_y']\n",
    "\n",
    "            matched_id = results.set_index('QSTNUM_x')['ID'].to_dict()\n",
    "            print(f'Matched HHs (MIS{mis}): ', len(matched_id))\n",
    "            d.update(matched_id)\n",
    "\n",
    "            dft = dft.loc[~dft['QSTNUM'].isin(matched_id.keys())]\n",
    "\n",
    "        if len(search_list[mis]) > 0:\n",
    "            # Households with no match get current id, same has MIS=1\n",
    "            new_hh = dft[dft['HRMIS'] == mis]\n",
    "            new_hh['ID'] = new_hh['DATE'] * 100000 + new_hh['QSTNUM']\n",
    "            new_hh_d = new_hh.set_index('QSTNUM')['ID'].to_dict()\n",
    "            d.update(new_hh_d)\n",
    "            print(f'Replacement HHs (MIS{mis}): ', len(new_hh_d))\n",
    "            if len(new_hh_d) > 2000:\n",
    "                print('\\nWARNING too many replacements, CHECK!\\n')\n",
    "\n",
    "    print('Total IDs created:', len(d))\n",
    "    print('Total IDs not created:', tot_hh - len(d), '\\n\\n')\n",
    "\n",
    "    monthly_id_dict = {curr_mo: d}\n",
    "\n",
    "    # Save results\n",
    "    cps_ids_full.update(monthly_id_dict)\n",
    "\n",
    "\n",
    "# Write to file\n",
    "with open(ids_file, 'wb') as f:\n",
    "    pickle.dump(cps_ids_full, f)\n",
    "    \n",
    "print('Total months of IDs:', len(cps_ids_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
