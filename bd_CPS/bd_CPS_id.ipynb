{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique CPS Household ID \n",
    "\n",
    "February 9, 2019\n",
    "\n",
    "Brian Dew, @bd_econ\n",
    "\n",
    "-----\n",
    "\n",
    "Drawn primarily from the description of the IPUMS CPSID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T01:53:36.179392Z",
     "start_time": "2019-02-10T01:53:35.938633Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import preliminaries\n",
    "import os, re, struct, pickle, string\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "from bd_CPS_details import StatesMap, DataDict\n",
    "\n",
    "os.chdir('/home/brian/Documents/CPS/data')\n",
    "\n",
    "dd_matcher = pickle.load(open('cps_basic_dd.pkl', 'rb'))['matcher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T01:53:36.191498Z",
     "start_time": "2019-02-10T01:53:36.181273Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Return regex pattern that will parse data dictionary dd_file\n",
    "def return_dd_parser(dd_file):\n",
    "    \n",
    "    DataDict = {'January_2017_Record_Layout.txt': \n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'January_2015_Record_Layout.txt':\n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'January_2014_Record_Layout.txt':\n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'January_2013_Record_Layout.txt':\n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'may12dd.txt':\n",
    "                '\\n(\\w+)\\s+(\\d+)\\s+.*?\\t+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan10dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan09dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan07dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'augnov05dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'may04dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan03dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan98dd.asc':\n",
    "                'D (\\w+)\\s+(\\d{1,2})\\s+(\\d+)\\s+',\n",
    "                'jan98dd2.asc':\n",
    "                'D (\\w+)\\s+(\\d{1,2})\\s+(\\d+)\\s+',\n",
    "                'sep95_dec97_dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jun95_aug95_dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'apr94_may95_dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)',\n",
    "                'jan94_mar94_dd.txt':\n",
    "                '\\n(?:\\x0c)?(\\w+)\\s+(\\d+)\\s+.*? \\s+.*?(\\d\\d*).*?(\\d\\d+)'}\n",
    "    \n",
    "    return DataDict[dd_file]\n",
    "\n",
    "\n",
    "# Create HHID2 for pre May 2004 data\n",
    "def id2_gen(np_mo):\n",
    "    hrsample = [x[1:3] for x in np_mo['HRSAMPLE']]\n",
    "    hrsersuf = [x.strip() for x in np_mo['HRSERSUF']]\n",
    "    sersuf_d = {a: str(ord(a.lower()) - 96).zfill(2) for a in set(hrsersuf)\n",
    "            if a in list(string.ascii_letters)}\n",
    "    sersuf_d.update({'-1': '00', '-1.0': '00', '0': '00'})\n",
    "    sersuf = list(map(sersuf_d.get, hrsersuf))\n",
    "    np_mo.loc[np_mo['HUHHNUM'] < 0, 'HUHHNUM'] = 0\n",
    "    huhhnum = np_mo['HUHHNUM'].astype('U1')\n",
    "    \n",
    "    id2 = [''.join(i) for i in zip(hrsample, sersuf, huhhnum)]\n",
    "\n",
    "    return(np.array(id2, dtype='uint32'))\n",
    "\n",
    "# Rename HRHHID2\n",
    "def text_repl(vname):\n",
    "    return vname.replace('HRHHID (partII)', 'HRHHID2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T01:53:36.200784Z",
     "start_time": "2019-02-10T01:53:36.192629Z"
    }
   },
   "outputs": [],
   "source": [
    "file = 'may01pub.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T01:53:36.211634Z",
     "start_time": "2019-02-10T01:53:36.202985Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Details for matching new file to previous data\n",
    "curr_mo = pd.to_datetime(file[:5], format='%b%y')\n",
    "mo_diffs = [1, 2, 3, 9, 10, 11, 12, 13, 14, 15]\n",
    "poss_mos = [poss_mo for poss_mo in [curr_mo - pd.DateOffset(months=mo_diff)\n",
    "            for mo_diff in mo_diffs] \n",
    "            if poss_mo >= pd.to_datetime('1995-05-01')]\n",
    "\n",
    "years = list(set([pm.year for pm in poss_mos]))\n",
    "bd_CPS_files = [f'cps{year}.ft' for year in years]\n",
    "\n",
    "yymms = [int(pm.strftime('%y%m')) for pm in poss_mos]\n",
    "\n",
    "# Create mapping of MIS to potential match months\n",
    "yymms_rev = yymms[::-1]\n",
    "\n",
    "if len(poss_mos) == 10:  # Temporary if to prevent errors from 1995 break.\n",
    "    search_list = {\n",
    "        8: yymms_rev[:4] + yymms_rev[-3:],\n",
    "        7: yymms_rev[1:5] + yymms_rev[-2:],\n",
    "        6: yymms_rev[2:6] + yymms_rev[-1:],\n",
    "        5: yymms_rev[3:7],\n",
    "        4: yymms_rev[-3:],\n",
    "        3: yymms_rev[-2:],\n",
    "        2: yymms_rev[-1:]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T01:53:36.227928Z",
     "start_time": "2019-02-10T01:53:36.212977Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Dictionary Parsed Successfully\n"
     ]
    }
   ],
   "source": [
    "# Background to read current monthly file\n",
    "# read data dictionary text file \n",
    "dd_file = dd_matcher[file]\n",
    "data_dict = open(dd_file, 'r', encoding='iso-8859-1').read()\n",
    "\n",
    "# manually list out the IDs for series of interest \n",
    "var_names = ['HRMONTH', 'HRYEAR4', 'HRMIS', 'QSTNUM', 'OCCURNUM', \n",
    "             'HRHHID', 'HRHHID2', 'GESTFIPS', 'HWHHWGT']\n",
    "\n",
    "if curr_mo < pd.to_datetime('2005-08-01'):\n",
    "    var_names = ['HRMONTH', 'HRYEAR4', 'HRMIS', 'QSTNUM', 'OCCURNUM', \n",
    "                 'HRHHID', 'HRHHID (partII)', 'GESTFIPS', 'HWHHWGT']    \n",
    "    \n",
    "if curr_mo < pd.to_datetime('2004-05-01'):\n",
    "    var_names = ['HRMONTH', 'HRYEAR4', 'HRMIS', 'QSTNUM', 'OCCURNUM', \n",
    "                 'HRHHID', 'HRSAMPLE', 'HRSERSUF', 'HUHHNUM', 'GESTFIPS', \n",
    "                 'HWHHWGT']      \n",
    "\n",
    "# regular expression matching series name and data dict pattern\n",
    "p = return_dd_parser(dd_file)\n",
    "\n",
    "# pick data type based on size of variable\n",
    "def id_dtype(size, name):\n",
    "    size = int(size)\n",
    "    dtype = ('U4' if name in ['HRSAMPLE']\n",
    "             else 'U2' if name in ['HRSERSUF']\n",
    "             else 'intp' if size > 9 \n",
    "             else 'int32' if size > 4 \n",
    "             else 'int16' if size > 2 \n",
    "             else 'int8')\n",
    "    return dtype\n",
    "\n",
    "# dictionary of variable name: [start, end, and length + 's']\n",
    "if dd_file in ['jan98dd.asc', 'jan98dd2.asc']:\n",
    "    d = {s[0]: [int(s[2])-1, int(s[2])+int(s[1])-1, \n",
    "                f'{s[1]}s', id_dtype(s[1], s[0])] \n",
    "         for s in re.findall(p, data_dict) if s[0] in var_names}       \n",
    "elif dd_file == 'may04dd.txt':\n",
    "    d = {text_repl(s[0]): [int(s[2])-1, int(s[3]), \n",
    "                           f'{s[1]}s', id_dtype(s[1], s[0])] \n",
    "         for s in re.findall(p, data_dict) if s[0] in var_names}\n",
    "else:\n",
    "    d = {s[0]: [int(s[2])-1, int(s[3]), f'{s[1]}s', id_dtype(s[1], s[0])]\n",
    "     for s in re.findall(p, data_dict) if s[0] in var_names}\n",
    "\n",
    "if len(var_names) == len(d):\n",
    "    print('Data Dictionary Parsed Successfully')\n",
    "else:\n",
    "    print('Data Dictionary Parsing Error')\n",
    "\n",
    "# data types\n",
    "dtypes = [(k, v[-1]) for k, v in d.items()]\n",
    "\n",
    "# weight variable start and end location\n",
    "ws, we = d['HWHHWGT'][:2]\n",
    "\n",
    "# first occurance to set household start and end\n",
    "hs, he = d['OCCURNUM'][:2]\n",
    "\n",
    "# lists of variable starts, ends, and lengths\n",
    "start, end, width, dtype = zip(*d.values())\n",
    "\n",
    "# create list of which characters to skip in each row\n",
    "skip = ([f'{s - e}x' for s, e in zip(start, [0] + list(end[:-1]))])\n",
    "\n",
    "# create format string by joining skip and variable segments\n",
    "unpack_fmt = ''.join([j for i in zip(skip, width) for j in i])\n",
    "\n",
    "# struct can interpret row bytes with the format string\n",
    "unpacker = struct.Struct(unpack_fmt).unpack_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T01:53:36.553700Z",
     "start_time": "2019-02-10T01:53:36.229447Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total HHs in sample: 45899\n"
     ]
    }
   ],
   "source": [
    "# Read new monthly file\n",
    "data = [unpacker(row) for row in open(file, 'rb') \n",
    "        if (row[ws:we].strip() > b'0')\n",
    "        and (row[hs:he].strip() == b'1')]\n",
    "\n",
    "# Assign new date variable\n",
    "date = lambda x: (((x.HRYEAR4.astype(np.int32) * 100) + \n",
    "                  x.HRMONTH.astype(np.int8)) % 10000)\n",
    "\n",
    "# Convert to dataframe using specified weights\n",
    "df = (pd.DataFrame(np.array(data, dtype=dtypes))\n",
    "        .assign(DATE = date))\n",
    "\n",
    "if curr_mo < pd.to_datetime('2004-05-01'):\n",
    "    df['HRHHID2'] = id2_gen(df)\n",
    "\n",
    "# Rename HHIDs\n",
    "df = df.rename({'HRHHID': 'HHID', 'HRHHID2': 'HHID2'}, axis=1)\n",
    "    \n",
    "# Need to map state to state id codes\n",
    "df['STATE'] = df['GESTFIPS'].map(StatesMap)\n",
    "\n",
    "# Drop GESTFIPS and OCCURNUM\n",
    "df = df.drop(['GESTFIPS', 'OCCURNUM'], axis=1)\n",
    "print('Total HHs in sample:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T01:53:37.003404Z",
     "start_time": "2019-02-10T01:53:36.555449Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Read potential match data\n",
    "keep_cols = ['YEAR', 'MONTH', 'MIS', 'HHID', 'HHID2', 'QSTNUM', \n",
    "             'OCCURNUM', 'STATE']\n",
    "\n",
    "date = lambda x: (((x.YEAR.astype(np.int32) * 100) + \n",
    "                  x.MONTH.astype(np.int8)) % 10000)\n",
    "\n",
    "mdf = (pd.concat(\n",
    "    [(pd.read_feather(f'clean/cps{year}.ft', columns=keep_cols)\n",
    "        .query('OCCURNUM == 1')\n",
    "        .assign(DATE = date))\n",
    "     for year in years]))\n",
    "\n",
    "mdf = (mdf[mdf['DATE'].isin(yymms)].drop(['MONTH', 'YEAR'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-10T01:53:37.667370Z",
     "start_time": "2019-02-10T01:53:37.004769Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New HHs (MIS1): 5757\n",
      "Matched HHs (MIS2):  5444\n",
      "Replacement HHs (MIS2):  396\n",
      "Matched HHs (MIS3):  5295\n",
      "Matched HHs (MIS3):  356\n",
      "Replacement HHs (MIS3):  193\n",
      "Matched HHs (MIS4):  5188\n",
      "Matched HHs (MIS4):  323\n",
      "Matched HHs (MIS4):  139\n",
      "Replacement HHs (MIS4):  101\n",
      "Matched HHs (MIS5):  4503\n",
      "Matched HHs (MIS5):  259\n",
      "Matched HHs (MIS5):  93\n",
      "Matched HHs (MIS5):  62\n",
      "Replacement HHs (MIS5):  641\n",
      "Matched HHs (MIS6):  4559\n",
      "Matched HHs (MIS6):  249\n",
      "Matched HHs (MIS6):  100\n",
      "Matched HHs (MIS6):  65\n",
      "Matched HHs (MIS6):  650\n",
      "Replacement HHs (MIS6):  100\n",
      "Matched HHs (MIS7):  4438\n",
      "Matched HHs (MIS7):  252\n",
      "Matched HHs (MIS7):  111\n",
      "Matched HHs (MIS7):  76\n",
      "Matched HHs (MIS7):  646\n",
      "Matched HHs (MIS7):  107\n",
      "Replacement HHs (MIS7):  76\n",
      "Matched HHs (MIS8):  4477\n",
      "Matched HHs (MIS8):  286\n",
      "Matched HHs (MIS8):  105\n",
      "Matched HHs (MIS8):  53\n",
      "Matched HHs (MIS8):  608\n",
      "Matched HHs (MIS8):  68\n",
      "Matched HHs (MIS8):  55\n",
      "Replacement HHs (MIS8):  68\n",
      "Total IDs created: 45899\n"
     ]
    }
   ],
   "source": [
    "# Merge data\n",
    "d = {}\n",
    "\n",
    "# MIS = 1 households get current id\n",
    "dfmis1 = df.loc[df['HRMIS'] == 1, ['QSTNUM', 'DATE']]\n",
    "dfmis1['ID'] = dfmis1['DATE'] * 100000 + dfmis1['QSTNUM']\n",
    "mis1id = dfmis1.set_index('QSTNUM')['ID'].to_dict()\n",
    "d.update(mis1id)\n",
    "print('New HHs (MIS1):', len(d))\n",
    "\n",
    "df = df.loc[df['HRMIS'] > 1]\n",
    "dft = df\n",
    "\n",
    "# Loop over MIS and potentional matches to find matched id\n",
    "for mis in [2, 3, 4, 5, 6, 7, 8]:    \n",
    "    for pm in search_list[mis]:\n",
    "        results = (dft.loc[dft['HRMIS'] == mis]\n",
    "                      .merge(mdf[mdf['DATE'] == pm], \n",
    "                             on=['HHID', 'HHID2', 'STATE']))\n",
    "\n",
    "        results['ID'] = results['DATE_y'] * 100000 + results['QSTNUM_y']\n",
    "\n",
    "        matched_id = results.set_index('QSTNUM_x')['ID'].to_dict()\n",
    "        print(f'Matched HHs (MIS{mis}): ', len(matched_id))\n",
    "        d.update(matched_id)\n",
    "\n",
    "        dft = dft.loc[~dft['QSTNUM'].isin(matched_id.keys())]\n",
    "    \n",
    "    # Households with no match get current id, same has MIS=1\n",
    "    new_hh = dft[dft['HRMIS'] == mis]\n",
    "    new_hh['ID'] = new_hh['DATE'] * 100000 + new_hh['QSTNUM']\n",
    "    new_hh_d = new_hh.set_index('QSTNUM')['ID'].to_dict()\n",
    "    d.update(new_hh_d)\n",
    "    print(f'Replacement HHs (MIS{mis}): ', len(new_hh_d))\n",
    "    \n",
    "print('Total IDs created:', len(d))\n",
    "\n",
    "monthly_id_dict = {curr_mo: d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
